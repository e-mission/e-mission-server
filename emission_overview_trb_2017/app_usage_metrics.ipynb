{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is based on the pilot on the UC Berkeley campus in Fall 2017\n",
    "# To obtain the data that this is based on, for research and reproducibility,\n",
    "# request data from Sep 2017 to Dec 2017 using\n",
    "# https://github.com/e-mission/e-mission-server/wiki/Requesting-data-as-a-collaborator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arrow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import emission.storage.timeseries.aggregate_timeseries as estag\n",
    "import emission.storage.timeseries.timequery as estt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agts = estag.AggregateTimeSeries()\n",
    "sep_dec_tq_data_ts = estt.TimeQuery(\"data.ts\", arrow.get(\"2016-09-01\").timestamp, arrow.get(\"2016-12-31\").timestamp)\n",
    "print arrow.get(sep_dec_tq_data_ts.startTs), \"->\", arrow.get(sep_dec_tq_data_ts.endTs), \"=\", sep_dec_tq_data_ts.get_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the server API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server_api_calls_df = agts.get_data_df(\"stats/server_api_time\", time_query=sep_dec_tq_data_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(server_api_calls_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server_api_calls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server_api_calls_df['fmt_utc_time'] = server_api_calls_df.ts.apply(lambda t: arrow.get(t).format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server_api_calls_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into timeline and non-timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of the calls are of the form `POST_/timeline/getTrips/2016-12-28`. These are all just calls to read the timeline, but because the id is part of the URL, they are treated as unique. Let's split them from the other callbacks so that we can see which calls actually happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_api_calls = pd.Series(server_api_calls_df.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_api_calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeline_call_mask = np.empty(len(unique_api_calls))\n",
    "timeline_call_mask.fill(False)\n",
    "# Needed because if it is not there, fill(False) fills with zeros\n",
    "# I have no idea why. Double negation fixes it.\n",
    "timeline_call_mask = np.logical_not(np.logical_not(timeline_call_mask))\n",
    "print timeline_call_mask[0:5]\n",
    "len(timeline_call_mask), len(unique_api_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, call in enumerate(unique_api_calls):\n",
    "    if call.startswith(\"POST_/timeline\"):\n",
    "        timeline_call_mask[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(timeline_call_mask), np.count_nonzero(np.logical_not(timeline_call_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeline_call_mask[0:5], np.logical_not(timeline_call_mask)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_api_calls[timeline_call_mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeline_calls_list = list(unique_api_calls[timeline_call_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_timeline_calls_list = list(unique_api_calls[np.logical_not(timeline_call_mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeline_calls_list[0:5], non_timeline_calls_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_timeline_calls_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some sanity checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only supposed to have data from this Sept to this Dec, at which time the apps in the stores were the latest version, but we still see calls to `/tripManager/getUnclassifiedSections` and `/compare`, which were calls from the old version of the apps. Amazingly enough, we even see a `_/movesCallback`, which is generated while signing in to the old app. Who was installing the old app after we switched to the new one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server_api_calls_df[server_api_calls_df.name == \"POST_/compare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server_api_calls_df[server_api_calls_df.name == \"POST_/movesCallback\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server_api_calls_df[server_api_calls_df.name == \"POST_/profile/settings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server_api_calls_df[server_api_calls_df.name == \"POST_/profile/consent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like somebody installed the old app around the 26th of Oct, and some people were using previously installed versions of the app through Oct. I wonder how they got access to it. But it is also pretty clear that I can ignore these for the purposes of this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading client stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client_nav_events_df = agts.get_data_df(\"stats/client_nav_event\", time_query=sep_dec_tq_data_ts)\n",
    "# client_times_df = agts.get_data_df(\"stats/client_time\", time_query=sep_dec_tq_data_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_times_df = agts.get_data_df(\"stats/client_time\", time_query=sep_dec_tq_data_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of users who signed up in this time frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get the number of calls to `/profile/create`. This is the number of sign-ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile_create_api_calls_df = server_api_calls_df[server_api_calls_df.name == 'POST_/profile/create']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile_create_api_calls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_profile_create_api_calls = len(profile_create_api_calls_df)\n",
    "n_profile_create_api_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The profile create call is not associated with a user_id, so we can't see how many unique calls there were. But it is a reasonable proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique userids making calls in this timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_userid_calls = server_api_calls_df.user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_userid_calls[0:5], unique_userid_calls[-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_userid_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_unique_userid_calls = len(unique_userid_calls)\n",
    "n_unique_userid_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This includes all users who were active during that time, not just users who signed up during that time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique userids making calls to `/usercache/put` in this timeframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it looks like there are still some calls from old clients, let's see if we can look at unique active users from the new client. We pick the `/usercache/put` call as a proxy because if there were no calls to it, we got no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usercache_put_api_calls_df = server_api_calls_df[server_api_calls_df.name == 'POST_/usercache/put']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usercache_put_api_calls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_unique_userid_usercache_put_calls = len(usercache_put_api_calls_df.user_id.unique())\n",
    "n_unique_userid_usercache_put_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of people who signed up for the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "habitica_register_api_calls_df = server_api_calls_df[server_api_calls_df.name == 'POST_/habiticaRegister']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_unique_userid_habitica_register_calls = len(habitica_register_api_calls_df.user_id.unique())\n",
    "n_unique_userid_habitica_register_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: Installation numbers according to various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_dict = {'Number of sign-ups': n_profile_create_api_calls,\n",
    "               'Number of calls from unique users': n_unique_userid_calls,\n",
    "                                        'Number of unique users with new clients': n_unique_userid_usercache_put_calls,\n",
    "                                        'Number of unique sign-ups for the game': n_unique_userid_habitica_register_calls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "installation_numbers_df = pd.DataFrame(columns=[\"users\"])\n",
    "for k, v in result_dict.items():\n",
    "    print \"Adding %s -> %s\" % (k, v)\n",
    "    installation_numbers_df.loc[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_indf = installation_numbers_df.sort_values(by='users', ascending=False)\n",
    "sorted_indf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_indf.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_indf.plot(kind='bar', figsize=(18, 6), rot=0, fontsize=10)\n",
    "# plt.tick_params(axis='x', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: sign-ups versus time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive graph of response time versus ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile_create_api_calls_df.plot(kind=\"bar\", x=\"ts\", y=\"reading\", figsize=(16,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to switch to a timestamp object instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile_create_api_calls_df['pd_ts'] = profile_create_api_calls_df.ts.apply(lambda t: pd.Timestamp(t, unit='s'))\n",
    "profile_create_api_calls_df['count_col'] = np.ones(len(profile_create_api_calls_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile_create_api_calls_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the graph looks like now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile_create_api_calls_df.plot(kind=\"bar\", x=\"pd_ts\", y=\"reading\", figsize=(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile_create_api_calls_df.plot(kind=\"bar\", x=\"pd_ts\", y=\"count_col\", figsize=(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's group by day to have it make sense\n",
    "# Similar to https://stackoverflow.com/questions/15297053/how-can-i-divide-single-values-of-a-dataframe-by-monthly-averages\n",
    "daily_profile_create_api = pd.Series()\n",
    "grouper = pd.Grouper(key='pd_ts', freq='D')\n",
    "grouped_result = profile_create_api_calls_df.groupby(grouper)\n",
    "for g in grouped_result:\n",
    "    print \"%s -> %s\" % (g[0], g[1].count_col.count())\n",
    "    daily_profile_create_api.loc[g[0]] = g[1].count_col.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = daily_profile_create_api.plot(kind='bar', figsize=(16,6), fontsize=12)\n",
    "ax.set_xlabel(\"Date\", fontsize=15)\n",
    "ax.xaxis.set_major_formatter(plt.FixedFormatter(daily_profile_create_api.index.to_series().dt.strftime(\"%d %b %Y\")))\n",
    "ax.set_ylabel(\"number of sign-up calls per day\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length of install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough algorithm:\n",
    "for each user, find the first and last call to `/usercache/put`. difference between them is the length of install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis for a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "# def get_install_length(user_id):\n",
    "user_usercache_put_calls = server_api_calls_df[(server_api_calls_df.name == 'POST_/usercache/put') & (server_api_calls_df.user_id == UUID('30ede46c-3b80-4ebb-aa3a-38e78e3c08d7'))]\n",
    "user_usercache_put_calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_user_usercache_put_calls = user_usercache_put_calls.sort_values(by=\"ts\", ascending=True)\n",
    "sorted_user_usercache_put_calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_user_usercache_put_calls.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_ts = sorted_user_usercache_put_calls.ts.iloc[0]\n",
    "last_ts = sorted_user_usercache_put_calls.ts.iloc[-1]\n",
    "delta = last_ts - first_ts\n",
    "duration = pd.Timedelta(delta, unit='s')\n",
    "delta, duration, duration.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But note that the last entries are around the end of our analysis time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_dt = pd.to_datetime(last_ts, unit='s')\n",
    "last_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_dt.month, last_dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final function for a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_install_length(user_id):\n",
    "    user_usercache_put_calls = server_api_calls_df[(server_api_calls_df.name == 'POST_/usercache/put') & (server_api_calls_df.user_id == user_id)]\n",
    "    if len(user_usercache_put_calls) == 0:\n",
    "        return 0\n",
    "    sorted_user_usercache_put_calls = user_usercache_put_calls.sort_values(by=\"ts\", ascending=True)\n",
    "    first_ts = sorted_user_usercache_put_calls.ts.iloc[0]\n",
    "    last_ts = sorted_user_usercache_put_calls.ts.iloc[-1]\n",
    "    print \"considering duration %s -> %s\" % (arrow.get(first_ts), arrow.get(last_ts))\n",
    "    last_dt = pd.to_datetime(last_ts, unit='s')\n",
    "    if last_dt.month == 12 and last_dt.day > 29:\n",
    "        return sys.maxint\n",
    "    else:\n",
    "        delta = last_ts - first_ts\n",
    "        duration = pd.Timedelta(delta, unit='s')\n",
    "        return duration.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get make a new dataframe for the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "install_duration = pd.DataFrame(columns=[\"start_ts\", \"end_ts\", \"duration\"])\n",
    "for u in usercache_put_api_calls_df.user_id.unique():\n",
    "    start_end_duration = get_install_length(u)\n",
    "    print \"%s -> %s\" % (u, start_end_duration)\n",
    "    install_duration.loc[u] = start_end_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "install_duration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "install_duration[install_duration.duration == sys.maxint].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "install_duration[install_duration.duration == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_install_duration = install_duration[install_duration.duration != sys.maxint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = display_install_duration.duration.plot(kind='hist', label='Number of users', fill=False, figsize=(16,6), bins=100, fontsize=12)\n",
    "ax2 = display_install_duration.duration.plot(kind='hist', label=\"Cumulative users\", ax=ax, cumulative=-1, normed=True, histtype='step', secondary_y=True, bins=100)\n",
    "ax.set_xlabel(\"Install duration\", fontsize=15)\n",
    "ax.set_ylabel(\"Number of users\", fontsize=15)\n",
    "# ax.axhline(y=23, color='black')\n",
    "ax.text(40, 15, \"23 users did not uninstall, install duration unknown\")\n",
    "ax.annotate(\"Spurious installs?\", xy=(0,16), xytext=(5,15), arrowprops=dict(facecolor='black', shrink=0.1))\n",
    "ax2.set_ylabel(\"Cumulative percentile of users\", fontsize=15, color='g')\n",
    "ax2.axhline(y=0.85, label=\"0.5\", color='m')\n",
    "ax2.text(90, 0.85, \"85%\", color='m')\n",
    "ax2.axhline(y=0.5, label=\"0.5\", color='r')\n",
    "ax2.text(90, 0.5, \"50%\", color='r')\n",
    "ax2.axhline(y=0.3, label=\"0.3\", color='b')\n",
    "ax2.text(90, 0.3, \"30%\", color='b')\n",
    "ax.axvline(x=3, color='m')\n",
    "ax.text(3, 5, \"3 days\", color='m')\n",
    "ax.axvline(x=20, color='r')\n",
    "ax.text(20, 5, \"20 days\", color='r')\n",
    "ax.axvline(x=38, color='b')\n",
    "ax.text(38, 5, \"38 days\", color='b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of times app was launched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One way: look at calls to the dashboard.\n",
    "\n",
    "this can either be `/result/metrics/timestamp` or `/result/metrics/local_date`\n",
    "\n",
    "Let's figure out which one is the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_timestamp_calls = server_api_calls_df[server_api_calls_df.name == 'POST_/result/metrics/timestamp']\n",
    "metrics_timestamp_calls.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server_api_calls_df[server_api_calls_df.name == 'POST_/result/metrics/local_date'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamp is clearly the default and there were 6207 opens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second way: look at `app_launched` stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_launched_events = client_nav_events_df[client_nav_events_df.name == \"app_launched\"]\n",
    "app_launched_events.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_timestamp_calls['pd_ts'] = metrics_timestamp_calls.ts.apply(lambda t: pd.Timestamp(t, unit='s'))\n",
    "app_launched_events['pd_ts'] = app_launched_events.ts.apply(lambda t: pd.Timestamp(t, unit='s'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Briefly try to explore the discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_timestamp_calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_launched_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_timestamp_calls[metrics_timestamp_calls.user_id == UUID('68d16b1a-1521-4eaf-922a-20ba037cdc79')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_launched_events[app_launched_events.user_id == UUID('68d16b1a-1521-4eaf-922a-20ba037cdc79')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the server calls are more accurate, let's use them for the next analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1: plot both on the same graph, let's group by day again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's group by day to have it make sense\n",
    "# Similar to https://stackoverflow.com/questions/15297053/how-can-i-divide-single-values-of-a-dataframe-by-monthly-averages\n",
    "daily_launches = pd.Series()\n",
    "grouper = pd.Grouper(key='pd_ts', freq='w')\n",
    "for g in metrics_timestamp_calls.groupby(grouper):\n",
    "    print \"%s -> %s\" % (g[0], g[1].ts.count())\n",
    "    daily_launches.loc[g[0]] = g[1].ts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = daily_launches.plot(kind='bar', figsize=(16,6), fontsize=12)\n",
    "ax.set_xlabel(\"Date\", fontsize=15)\n",
    "ax.xaxis.set_major_formatter(plt.FixedFormatter(daily_launches.index.to_series().dt.strftime(\"%d %b %Y\")))\n",
    "ax.set_ylabel(\"number of app launch calls per week\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_calls = pd.Series()\n",
    "for g in metrics_timestamp_calls.groupby(by=\"user_id\"):\n",
    "    print \"%s -> %s\" % (g[0], g[1].ts.count())\n",
    "    user_calls.loc[g[0]] = g[1].ts.count()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = user_calls[user_calls.index != ''].plot(kind='hist', label='Number of launches/user', fill=False, figsize=(16,6), bins=600, fontsize=12)\n",
    "ax2 = user_calls[user_calls.index != ''].plot(kind='hist', label=\"Cumulative fraction\", ax=ax, cumulative=-1, normed=True, histtype='step', secondary_y=True, bins=600)\n",
    "ax.set_xlabel(\"Number of app launches\", fontsize=15)\n",
    "ax.set_ylabel(\"Number of users\", fontsize=15)\n",
    "ax2.set_ylabel(\"Cumulative percentile of users\", fontsize=15, color='g')\n",
    "ax2.axhline(y=0.8, label=\"0.5\", color='r')\n",
    "ax2.text(550, 0.8, \"80%\", color='r')\n",
    "ax2.axhline(y=0.5, label=\"0.3\", color='b')\n",
    "ax2.text(550, 0.5, \"50%\", color='b')\n",
    "ax2.axhline(y=0.1, label=\"0.1\", color='m')\n",
    "ax2.text(550, 0.1, \"10%\", color='m')\n",
    "ax.axvline(x=5, color='r')\n",
    "ax.text(5, 11, \"5 launches\", color='r')\n",
    "ax.axvline(x=20, color='b')\n",
    "ax.text(20, 10, \"20 launches\", color='b')\n",
    "ax.axvline(x=150, color='m')\n",
    "ax.text(150, 9, \"150 launches\", color='m')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of times user navigated to another window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_changed_events = client_times_df[client_times_df.name == \"state_changed\"]\n",
    "print len(state_changed_events)\n",
    "state_changed_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Double negative to make it boolean instead of 0/1\n",
    "non_splash_mask = np.logical_not(np.logical_not(np.zeros(len(state_changed_events))))\n",
    "non_splash_mask[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_changed_events.reading.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, e in enumerate(state_changed_events.reading):\n",
    "    if \"splash\" in e:\n",
    "        non_splash_mask[i] = False\n",
    "    else:\n",
    "        non_splash_mask[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_splash_mask[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_changed_events.index[non_splash_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_splash_state_change_events = state_changed_events[state_changed_events.index.isin(state_changed_events.index[non_splash_mask])]\n",
    "non_splash_state_change_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_splash_state_change_events['pd_ts'] = non_splash_state_change_events.ts.apply(lambda t: pd.Timestamp(t, unit='s'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 2: Plot against time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's group by day to have it make sense\n",
    "# Similar to https://stackoverflow.com/questions/15297053/how-can-i-divide-single-values-of-a-dataframe-by-monthly-averages\n",
    "daily_screen_switches = pd.Series()\n",
    "grouper = pd.Grouper(key='pd_ts', freq='D')\n",
    "for g in non_splash_state_change_events.groupby(grouper):\n",
    "    print \"%s -> %s\" % (g[0], g[1].ts.count())\n",
    "    daily_screen_switches.loc[g[0]] = g[1].ts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = daily_screen_switches.plot(kind='bar', figsize=(16,6), fontsize=12)\n",
    "ax.set_xlabel(\"Date\", fontsize=15)\n",
    "ax.xaxis.set_major_formatter(plt.FixedFormatter(daily_screen_switches.index.to_series().dt.strftime(\"%d %b %Y\")))\n",
    "ax.set_ylabel(\"number of screen switches per day\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
