{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook runs cross-validation for all clustering methods so we can compare them in one handy location. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "import emission.storage.timeseries.abstract_timeseries as esta\n",
                "import emission.storage.decorations.trip_queries as esdtq\n",
                "import emission.core.get_database as edb\n",
                "from performance_eval import get_clf_metrics, cv_for_all_algs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### load data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_users = esta.TimeSeries.get_uuid_list()\n",
                "confirmed_trip_df_map = {}\n",
                "labeled_trip_df_map = {}\n",
                "expanded_labeled_trip_df_map = {}\n",
                "expanded_all_trip_df_map = {}\n",
                "for u in all_users:\n",
                "    ts = esta.TimeSeries.get_time_series(u)\n",
                "    ct_df = ts.get_data_df(\"analysis/confirmed_trip\")\n",
                "\n",
                "    confirmed_trip_df_map[u] = ct_df\n",
                "    labeled_trip_df_map[u] = esdtq.filter_labeled_trips(ct_df)\n",
                "    expanded_labeled_trip_df_map[u] = esdtq.expand_userinputs(\n",
                "        labeled_trip_df_map[u])\n",
                "    expanded_all_trip_df_map[u] = esdtq.expand_userinputs(\n",
                "        confirmed_trip_df_map[u])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### run evaluations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cv_results = cv_for_all_algs(\n",
                "    uuid_list=all_users,\n",
                "    expanded_trip_df_map=expanded_labeled_trip_df_map,\n",
                "    model_names=[\n",
                "        'old clustering', 'new clustering by combo r100m',\n",
                "        'new clustering by end r100m', 'new clustering by trip r100m',\n",
                "        'new clustering by combo r150m', 'new clustering by end r150m',\n",
                "        'new clustering by trip r150m',\n",
                "        'random forest with end and trip r150m',\n",
                "        'random forest with end and trip r100m',\n",
                "        'random forest with end and trip, drop unclustered r150m',\n",
                "        'random forest with end r100m',\n",
                "        'random forest with end and trip, drop unclustered r100m',\n",
                "        'random forest with start and end r100m',\n",
                "        'random forest with start end trip r100m', 'adaboost basic', 'random forest, no clustering'\n",
                "    ],\n",
                "    override_prior_runs=False,\n",
                "    raise_errors=False,\n",
                "    random_state=42,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# store results for all models in a nice dataframe\n",
                "all_model_results = {\n",
                "    ('model_name', ''): [],\n",
                "    ('trips without prediction', 'mode'): [],\n",
                "    ('trips without prediction', 'purpose'): [],\n",
                "    ('trips without prediction', 'replaced'): [],\n",
                "    ('accuracy overall', 'mode'): [],\n",
                "    ('accuracy overall', 'purpose'): [],\n",
                "    ('accuracy overall', 'replaced'): [],\n",
                "    ('accuracy of trips w predictions', 'mode'): [],\n",
                "    ('accuracy of trips w predictions', 'purpose'): [],\n",
                "    ('accuracy of trips w predictions', 'replaced'): [],\n",
                "    ('f1 weighted', 'mode'): [],\n",
                "    ('f1 weighted', 'purpose'): [],\n",
                "    ('f1 weighted', 'replaced'): [],\n",
                "}\n",
                "\n",
                "for model_name in cv_results.keys():\n",
                "    print(f'now evaluating: {model_name}')\n",
                "    all_model_results[('model_name', '')] += [model_name]\n",
                "    for label_type in ['mode', 'purpose', 'replaced']:\n",
                "        # get results\n",
                "        results = get_clf_metrics(cv_results[model_name],\n",
                "                                  label_type,\n",
                "                                  keep_nopred=True,\n",
                "                                  ignore_custom=False)\n",
                "\n",
                "        # update our dict of aggregate results\n",
                "        all_model_results[('trips without prediction', label_type)] += [\n",
                "            results['n_trips_without_prediction']\n",
                "        ]\n",
                "        all_model_results[('accuracy overall',\n",
                "                           label_type)] += [results['accuracy']]\n",
                "        all_model_results[('accuracy of trips w predictions', label_type)] += [\n",
                "            results['accuracy'] * len(results['label_true']) /\n",
                "            (len(results['label_true']) -\n",
                "             results['n_trips_without_prediction'])\n",
                "        ]\n",
                "        all_model_results[('f1 weighted',\n",
                "                           label_type)] += [results['weighted_f_score']]\n",
                "\n",
                "all_model_results_df = pd.DataFrame(all_model_results)\n",
                "all_model_results_df\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "73ac5b45931ab4dd3f8e07a8d0e5daf0146eed4821bf42374f6ac6fa4af28c83"
        },
        "kernelspec": {
            "display_name": "Python 3.7.12 ('emission-private-eval')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
