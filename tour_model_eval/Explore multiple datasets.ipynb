{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finnish-despite",
   "metadata": {},
   "source": [
    "# Explore multiple datasets\n",
    "\n",
    "In this notebook, we are going to experiment with characterising the three datasets that we have in terms of data quality and demographic characteristics.\n",
    "\n",
    "This notebook is intended to be run on the exported, federated csv file. The file should be exported using `Federating and saving multiple datasets.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-seventh",
   "metadata": {},
   "source": [
    "### First, we read the data and extract the most common purpose labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geojson as gj\n",
    "import sklearn.cluster as sc\n",
    "import sklearn.metrics.pairwise as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import branca.element as bre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from uuid import UUID\n",
    "\n",
    "import bson.json_util as bju\n",
    "import bson.objectid as boi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.decorations.trip_queries as esdtq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-april",
   "metadata": {},
   "source": [
    "### Read data and setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_expanded_df = pd.read_json(open(\"/tmp/federated_trip_only_dataset.json\"), orient=\"records\", typ=\"frame\")\n",
    "for id_col in [\"_id\", \"raw_trip\", \"start_place\", \"end_place\", \"cleaned_trip\"]:\n",
    "    all_expanded_df[id_col] = all_expanded_df[id_col].apply(lambda i: boi.ObjectId(i[\"$oid\"]))\n",
    "    \n",
    "all_expanded_df[\"user_id\"] = all_expanded_df[\"user_id\"].apply(lambda u: UUID(u[\"$uuid\"]))\n",
    "all_expanded_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_expanded_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_program(user_id):\n",
    "    all_programs = all_expanded_df[all_expanded_df.user_id == user_id][\"program\"].unique()\n",
    "    assert len(all_programs) == 1, f\"all_programs = {all_programs}\"\n",
    "    return all_programs[0]\n",
    "\n",
    "participant_df = pd.DataFrame(all_expanded_df.user_id.unique(), columns=[\"user_id\"])\n",
    "participant_df = participant_df[participant_df.user_id != 0]\n",
    "participant_df.set_index(\"user_id\", inplace=True, drop=True)\n",
    "participant_df[\"program\"] = [get_unique_program(u) for u in participant_df.index]\n",
    "participant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_support_objects = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_RADIUS = 500\n",
    "FINAL_POINT_DBSCAN = sc.DBSCAN(FINAL_RADIUS, min_samples=2, metric=\"precomputed\")\n",
    "FINAL_TRIP_DBSCAN = sc.DBSCAN(FINAL_RADIUS * 2, min_samples=2, metric=\"precomputed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-retail",
   "metadata": {},
   "source": [
    "### Standard functions (currently copied over from other notebooks; should be refactored into a python file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc_df(loc_series):\n",
    "    loc_df = pd.DataFrame(loc_series.apply(lambda p: p[\"coordinates\"]).to_list(), columns=[\"longitude\", \"latitude\"])\n",
    "    # display.display(end_loc_df.head())\n",
    "    return loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(loc_df):\n",
    "    EARTH_RADIUS = 6371000\n",
    "    radians_lat_lon = np.radians(loc_df[[\"latitude\", \"longitude\"]])\n",
    "    dist_matrix_meters = pd.DataFrame(smp.haversine_distances(radians_lat_lon, radians_lat_lon) * 6371000)\n",
    "    return dist_matrix_meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_loc_clusters(user_id, modeling_support_objects, trip_df):\n",
    "    user_trip_df = trip_df[trip_df.user_id == user_id]\n",
    "    start_distance_matrix = get_distance_matrix(get_loc_df(user_trip_df.start_loc))\n",
    "    end_distance_matrix = get_distance_matrix(get_loc_df(user_trip_df.end_loc))\n",
    "    start_loc_model = copy.copy(FINAL_POINT_DBSCAN).fit(start_distance_matrix)\n",
    "    end_loc_model = copy.copy(FINAL_POINT_DBSCAN).fit(end_distance_matrix)\n",
    "    trip_df.loc[user_trip_df.index, \"start_loc_cluster\"] = start_loc_model.labels_\n",
    "    trip_df.loc[user_trip_df.index, \"end_loc_cluster\"] = end_loc_model.labels_\n",
    "\n",
    "    curr_model_support = modeling_support_objects.get(user_id)\n",
    "    if curr_model_support is None:\n",
    "        modeling_support_objects[user_id] = {}\n",
    "        curr_model_support = modeling_support_objects[user_id]\n",
    "    curr_model_support[\"start_distance_matrix\"] = start_distance_matrix\n",
    "    curr_model_support[\"end_distance_matrix\"] = end_distance_matrix   \n",
    "    curr_model_support[\"start_loc_model\"] = start_loc_model\n",
    "    curr_model_support[\"end_loc_model\"] = end_loc_model\n",
    "\n",
    "    return trip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trip_clusters_dbscan(user_id, trip_df):\n",
    "    user_trip_df = trip_df[trip_df.user_id == user_id]\n",
    "    all_combos = user_trip_df.groupby([\"start_loc_cluster\", \"end_loc_cluster\"])\n",
    "    valid_combos = [p for p in all_combos.groups if p[0] != -1 and p[1] != -1]\n",
    "    print(f\"After validating, all_combos {len(all_combos.groups)} -> {len(valid_combos)}\")\n",
    "    all_combos_dict = dict(all_combos.groups)\n",
    "    valid_combos_series = pd.Series(valid_combos)\n",
    "    for g, idxlist in all_combos_dict.items():\n",
    "        print(g, idxlist)\n",
    "        match = valid_combos_series[valid_combos_series == g]\n",
    "        if len(match) == 0:\n",
    "            print(f\"invalid combo {g} found for entries {idxlist}, trip is not in a cluster\")\n",
    "            trip_df.loc[idxlist, \"trip_cluster_dbscan\"] = -1\n",
    "        else:\n",
    "            print(f\"valid combo {g} found for entries {idxlist}, setting trip cluster to {match.index[0]}\")\n",
    "            trip_df.loc[idxlist, \"trip_cluster_dbscan\"] = int(match.index[0])\n",
    "    return trip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_basic_stats(user_id, participant_df, trip_df):\n",
    "    user_trip_df = trip_df[trip_df.user_id == user_id]\n",
    "    basic_stats = {}\n",
    "    basic_stats[\"n_labeled_trips\"] = len(user_trip_df)\n",
    "    basic_stats[\"unique_label_combos\"] = list(user_trip_df.groupby([\"mode_confirm\", \"purpose_confirm\", \"replaced_mode\"]).groups)\n",
    "    basic_stats[\"start_loc_in_cluster\"] = np.count_nonzero(user_trip_df.start_loc_cluster != -1)\n",
    "    basic_stats[\"end_loc_in_cluster\"] = np.count_nonzero(user_trip_df.end_loc_cluster != 1)\n",
    "    basic_stats[\"trip_in_cluster_dbscan\"] = np.count_nonzero(user_trip_df.trip_cluster_dbscan != -1)\n",
    "    basic_stats[\"n_clusters_dbscan\"] = user_trip_df.trip_cluster_dbscan.max()\n",
    "    # print(f\"Adding cols {basic_stats.keys()} with vals {basic_stats.values()}\")\n",
    "    participant_df.loc[user_id, basic_stats.keys()] = basic_stats.values()\n",
    "    return participant_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-wrist",
   "metadata": {},
   "source": [
    "Target exploratory analysis:\n",
    "\n",
    "- number of users\n",
    "- number of trips\n",
    "- labeled trip/user distribution\n",
    "- number of unique combinations of labels\n",
    "- distribution of unique combination of labels (overall)\n",
    "- distribution of unique combination of labels (per-user)\n",
    "- number of trips whose end point is in a cluster\n",
    "- number of trips whose start point is in a cluster\n",
    "- number of trips where trip is in a cluster\n",
    "- number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in participant_df.index:\n",
    "    all_expanded_df = add_trip_clusters_dbscan(u, add_loc_clusters(u, modeling_support_objects,all_expanded_df))\n",
    "    participant_df = update_basic_stats(u, participant_df, all_expanded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-salmon",
   "metadata": {},
   "source": [
    "### Again, let's focus on one dataset before generalizing to other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "minipilot_df = participant_df[participant_df.program == \"minipilot\"]\n",
    "minipilot_df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "minipilot_df[[\"n_labeled_trips\", \"start_loc_in_cluster\", \"end_loc_in_cluster\", \"trip_in_cluster_dbscan\", \"n_clusters_dbscan\"]].plot(kind=\"bar\", figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-muscle",
   "metadata": {},
   "source": [
    "# Final results, generalized to the entire dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-river",
   "metadata": {},
   "source": [
    "### First, let's just display everything, without grouping by program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in participant_df.index:\n",
    "    all_expanded_df = add_trip_clusters_dbscan(u, add_loc_clusters(u, modeling_support_objects,all_expanded_df))\n",
    "    participant_df = update_basic_stats(u, participant_df, all_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-lodging",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "participant_df[[\"n_labeled_trips\", \"start_loc_in_cluster\", \"end_loc_in_cluster\", \"trip_in_cluster_dbscan\", \"n_clusters_dbscan\"]].plot(kind=\"bar\", use_index=False, figsize=(30,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-burlington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-lender",
   "metadata": {},
   "source": [
    "### Next, let's group by dataframe to see if there are consistent program level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df[participant_df.program == \"minipilot\"][[\"n_labeled_trips\", \"start_loc_in_cluster\", \"end_loc_in_cluster\", \"trip_in_cluster_dbscan\", \"n_clusters_dbscan\"]].plot(kind=\"bar\", figsize=(20,5), use_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df[participant_df.program == \"nrel_lh\"][[\"n_labeled_trips\", \"start_loc_in_cluster\", \"end_loc_in_cluster\", \"trip_in_cluster_dbscan\", \"n_clusters_dbscan\"]].plot(kind=\"bar\", figsize=(20,5), use_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df[participant_df.program == \"stage\"][[\"n_labeled_trips\", \"start_loc_in_cluster\", \"end_loc_in_cluster\", \"trip_in_cluster_dbscan\", \"n_clusters_dbscan\"]].plot(kind=\"bar\", figsize=(20,5), use_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-diagnosis",
   "metadata": {},
   "source": [
    "### Assessing clustering effectiveness\n",
    "\n",
    "Assuming that fewer clusters are better than more because there is more commonality, we can display the ratio of clusters to trips in clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df[\"cluster_trip_ratio\"] = participant_df[\"n_clusters_dbscan\"] / participant_df[\"trip_in_cluster_dbscan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using plt.scatter here instead of pandas.plot since it is non-trivial to use the index as the x axis\n",
    "# https://stackoverflow.com/questions/49834883/scatter-plot-form-dataframe-with-index-on-x-axis\n",
    "# x=df.index does not work for me, may be due to an older version of pandas\n",
    "color_list = plt.get_cmap(\"Accent\", 3).colors\n",
    "fig = plt.Figure(figsize=(10,5))\n",
    "for i, p in enumerate(participant_df.program.unique()):\n",
    "    curr_p_df = participant_df[participant_df.program==p]\n",
    "    fig = plt.scatter([str(u) for u in curr_p_df.index], curr_p_df[\"cluster_trip_ratio\"], color=color_list[i], label=p)\n",
    "fig.axes.set_xticklabels(range(0,len(participant_df)))\n",
    "fig.axes.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-passing",
   "metadata": {},
   "source": [
    "The NREL LH program does in fact have a better cluster ratio overall than the other two programs. But even in the other two programs, most of the ratios are pretty low. Still, we can't help everybody, and there are going to be a large number of people who are going to have to label more than half their trips. Still, it is gratifying to see that the max overall is just a bit higher than 0.7.\n",
    "\n",
    "The same data with a slightly different visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df.boxplot(\"cluster_trip_ratio\", by=\"program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-replication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
