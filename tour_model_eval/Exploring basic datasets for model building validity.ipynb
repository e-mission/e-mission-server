{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mechanical-hamburg",
   "metadata": {},
   "source": [
    "This compares model size and number of predictions for different model creation options and datasets.\n",
    "I should really merge this into the dataset evaluation, but that will require changing the JSON export to include unconfirmed trips, and I just want to get this done now.\n",
    "\n",
    "It assumes that the datasets are loaded into separate docker containers with ports exposed at 27071, 27018 and 27019.\n",
    "It requires re-introduction of a **hack** \n",
    "https://github.com/e-mission/e-mission-server/commit/4cf770e3e30af617b89f9fe6007298afc37c0dd6\n",
    "to allow re-loading of database connections\n",
    "\n",
    "\n",
    "TODO: Clean this up later after cleaning up the export code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.core.get_database as edb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e43fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.decorations.trip_queries as esdtq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.analysis.modelling.tour_model.data_preprocessing as old_preprocess\n",
    "import emission.analysis.modelling.tour_model_first_only.data_preprocessing as new_preprocess\n",
    "\n",
    "import emission.analysis.modelling.tour_model.get_users as old_users\n",
    "import emission.analysis.modelling.tour_model_first_only.get_users as new_users\n",
    "\n",
    "import emission.analysis.modelling.tour_model.evaluation_pipeline as old_ep\n",
    "import emission.analysis.modelling.tour_model_first_only.evaluation_pipeline as new_ep\n",
    "\n",
    "import emission.analysis.modelling.tour_model.load_predict as old_lp\n",
    "import emission.analysis.modelling.tour_model_first_only.load_predict as new_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.analysis.modelling.tour_model.label_processing as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ca954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just return a random split since their lengths should be roughly equal\n",
    "# and that way we don't have to run the evaluation pipeline first\n",
    "# and spend hours on it\n",
    "# Copied version to allow us to override old implementation on the fly :)\n",
    "def find_best_split_and_parameters(user,test_data):\n",
    "    import random\n",
    "    # find a random score\n",
    "    best_split_idx = random.choice(range(len(test_data)))\n",
    "    # use the position of best_score to find best_split\n",
    "    best_split = test_data[best_split_idx]\n",
    "    # use best_split_idx to find the best parameters\n",
    "    low = best_split_idx * 100\n",
    "    dist_pct = best_split_idx / 100\n",
    "    return best_split,best_split_idx,low,dist_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e797f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_location_map(trip_list, bins):\n",
    "    bin_loc_feat = {}\n",
    "    user_input_map = {}\n",
    "    for i, curr_bin in enumerate(bins):\n",
    "        # print(f\"Considering {curr_bin} for trip list of length {len(trip_list)}\")\n",
    "        bin_trips = [trip_list[j] for j in curr_bin]\n",
    "        # print(f\"Considering {bin_trips} for bin {curr_bin}\")\n",
    "        x = old_preprocess.extract_features(bin_trips)\n",
    "        bin_loc_feat[str(i)] = [feat[0:4] for feat in x]\n",
    "    return bin_loc_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ee385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_input_map(trip_list, bins):\n",
    "    # map from bin index to user input probabilities\n",
    "    # e.g. {\"0\": [{'labels': {'mode_confirm': 'drove_alone', 'purpose_confirm': 'work', 'replaced_mode': 'drove_alone'}, 'p': 1.0}]}\n",
    "    user_input_map = {}\n",
    "    for b, curr_bin in enumerate(bins):\n",
    "        bin_trips = [trip_list[j] for j in curr_bin]\n",
    "        user_label_df = pd.DataFrame([trip['data']['user_input'] for trip in bin_trips])\n",
    "        # user_label_df = lp.map_labels(user_label_df)\n",
    "        # compute the sum of trips in this cluster\n",
    "        sum_trips = len(user_label_df)\n",
    "        # compute unique label sets and their probabilities in one cluster\n",
    "        # 'p' refers to probability\n",
    "        unique_labels = user_label_df.groupby(user_label_df.columns.tolist()).size().reset_index(name='uniqcount')\n",
    "        unique_labels['p'] = unique_labels.uniqcount / sum_trips\n",
    "        labels_columns = user_label_df.columns.to_list()\n",
    "        bin_label_combo_list = []\n",
    "        for i in range(len(unique_labels)):\n",
    "            one_set_labels = {}\n",
    "            # e.g. labels_only={'mode_confirm': 'pilot_ebike', 'purpose_confirm': 'work', 'replaced_mode': 'walk'}\n",
    "            labels_only = {column: unique_labels.iloc[i][column] for column in labels_columns}\n",
    "            one_set_labels[\"labels\"] = labels_only\n",
    "            one_set_labels['p'] = unique_labels.iloc[i]['p']\n",
    "            # e.g. one_set_labels = {'labels': {'mode_confirm': 'walk', 'replaced_mode': 'walk', 'purpose_confirm': 'exercise'}, 'p': 1.0}\n",
    "            bin_label_combo_list.append(one_set_labels)\n",
    "        user_input_map[str(b)] = bin_label_combo_list\n",
    "    return user_input_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19697f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bin(trip, bin_locations, radius):\n",
    "    trip_feat = new_preprocess.extract_features([trip])[0]\n",
    "    trip_loc_feat = trip_feat[0:4]\n",
    "    first_round_label_set = list(bin_locations.keys())\n",
    "    sel_fl = None\n",
    "    for fl in first_round_label_set:\n",
    "        # extract location features of selected bin\n",
    "        sel_loc_feat = bin_locations[fl]\n",
    "        # Check if start/end locations of the new trip and every start/end locations in this bin are within the range of\n",
    "        # radius. If so, the new trip falls in this bin. Then predict the second round label of the new trip\n",
    "        # using this bin's model\n",
    "        if old_lp.in_bin(sel_loc_feat, trip_loc_feat, radius):\n",
    "            sel_fl = fl\n",
    "            break\n",
    "    if not sel_fl:\n",
    "        logging.debug(f\"sel_fl = {sel_fl}, early return\")\n",
    "        return -1\n",
    "    return sel_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_stats(program, uuid_list):\n",
    "    curr_dataset_validity_stats = []\n",
    "    for u in uuid_list:\n",
    "        curr_validity_stats = {\"program\": program, \"user_id\": u}\n",
    "        trips = old_preprocess.read_data(u)\n",
    "        # print([t for t in trips if \"user_input\" not in t[\"data\"]])\n",
    "        unlabeled_trips = [t for t in trips if t[\"data\"][\"user_input\"] == {}]\n",
    "        print(f\"For {u} in {program}, read {len(trips)}\")\n",
    "        curr_validity_stats[\"all_trip_count_old\"] = len(trips)\n",
    "        curr_validity_stats[\"unlabeled_trip_count_old\"] = len(unlabeled_trips)\n",
    "        filter_trips = old_preprocess.filter_data(trips, 100)\n",
    "        curr_validity_stats[\"valid_trip_count_old\"] = len(filter_trips)\n",
    "        curr_validity_stats[\"valid_user_old\"] = old_users.valid_user(filter_trips, trips)\n",
    "        if old_users.valid_user(filter_trips, trips):\n",
    "            tune_idx, test_idx = old_preprocess.split_data(filter_trips)\n",
    "            test_data = old_preprocess.get_subdata(filter_trips, tune_idx)\n",
    "            best_split, best_split_idx, low, dist_pct = find_best_split_and_parameters(u,test_data)\n",
    "            sim, bins, bin_trips, filter_trips = old_ep.first_round(best_split, 100)\n",
    "            curr_validity_stats[\"bins_old\"] = len(bins)\n",
    "            curr_validity_stats[\"bin_trips_old\"] = len(bin_trips)\n",
    "            curr_validity_stats[\"model_input_trips_old\"] = len(bin_trips)\n",
    "            print(f\"Creating model maps for {bins} and {len(bin_trips)}\")\n",
    "            bin_loc_feat = create_location_map(filter_trips, bins)\n",
    "            user_input_map = create_user_input_map(filter_trips, bins)\n",
    "            pred_bin_list = [find_bin(t, bin_loc_feat, 100) for t in trips]\n",
    "            print(f\"Found old predicted bins {pred_bin_list}\")\n",
    "            curr_validity_stats[\"predicted_trips_all_old\"] = np.count_nonzero(pd.Series(pred_bin_list) != -1)\n",
    "            pred_bin_list = [find_bin(t, bin_loc_feat, 100) for t in unlabeled_trips]\n",
    "            print(f\"Found old unlabeled predicted bins {pred_bin_list}\")\n",
    "            curr_validity_stats[\"predicted_trips_unlabeled_old\"] = np.count_nonzero(pd.Series(pred_bin_list) != -1)\n",
    "            user_input_pred_list = [user_input_map[pb] for pb in pred_bin_list if pb != -1]\n",
    "            # print(f\"User predictions for unlabeled trips are {user_input_pred_list}\")\n",
    "        else:\n",
    "            curr_validity_stats[\"bins_old\"] = 0\n",
    "            curr_validity_stats[\"bin_trips_old\"] = 0\n",
    "            curr_validity_stats[\"model_input_trips_old\"] = 0\n",
    "\n",
    "        # print(f\"Finished iterating over old, starting with new....\")\n",
    "        trips = new_preprocess.read_data(u)\n",
    "        unlabeled_trips = [t for t in trips if t[\"data\"][\"user_input\"] == {}]\n",
    "\n",
    "        curr_validity_stats[\"all_trip_count_new\"] = len(trips)\n",
    "        curr_validity_stats[\"unlabeled_trip_count_new\"] = len(unlabeled_trips)\n",
    "        filter_trips = new_preprocess.filter_data(trips, 500)\n",
    "        curr_validity_stats[\"valid_trip_count_new\"] = len(filter_trips)\n",
    "        curr_validity_stats[\"valid_user_new\"] = new_users.valid_user(filter_trips, trips)\n",
    "        sim, bins, bin_trips, filter_trips = new_ep.first_round(filter_trips, 500)\n",
    "        curr_validity_stats[\"bins_new\"] = len(bins)\n",
    "        curr_validity_stats[\"bin_trips_new\"] = len(bin_trips)\n",
    "        curr_validity_stats[\"model_input_trips_new\"] = len(bin_trips)\n",
    "        print(f\"Creating model maps for {len(bin_trips)}\")\n",
    "        bin_loc_feat = create_location_map(filter_trips, bins)\n",
    "        user_input_map = create_user_input_map(filter_trips, bins)\n",
    "        pred_bin_list = [find_bin(t, bin_loc_feat, 500) for t in trips]\n",
    "        print(f\"Found new predicted bins {pred_bin_list}\")\n",
    "        curr_validity_stats[\"predicted_trips_all_new\"] = np.count_nonzero(pd.Series(pred_bin_list) != -1)\n",
    "        pred_bin_list = [find_bin(t, bin_loc_feat, 500) for t in filter_trips]\n",
    "        assert len(pred_bin_list) == len(filter_trips)\n",
    "        pred_bin_list = [find_bin(t, bin_loc_feat, 500) for t in unlabeled_trips]\n",
    "        print(f\"Found new unlabeled predicted bins {pred_bin_list}\")\n",
    "        curr_validity_stats[\"predicted_trips_unlabeled_new\"] = np.count_nonzero(pd.Series(pred_bin_list) != -1)\n",
    "\n",
    "        curr_dataset_validity_stats.append(curr_validity_stats)\n",
    "    return curr_dataset_validity_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_stats = model_validity_stats + get_dataset_stats(\"minipilot\", esta.TimeSeries.get_uuid_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "esta.TimeSeries._reset_url(\"localhost:27018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_stats = model_validity_stats + get_dataset_stats(\"nrel-lh\", esta.TimeSeries.get_uuid_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "edb.get_profile_db().distinct(\"client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "esta.TimeSeries._reset_url(\"localhost:27019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_stats = model_validity_stats + get_dataset_stats(\"stage\", esta.TimeSeries.get_uuid_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35dc25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_stats_df = pd.DataFrame(model_validity_stats); model_validity_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_stats_df.plot(kind=\"bar\", y=[\"all_trip_count_old\", \"all_trip_count_new\"],figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_stats_df.plot(kind=\"bar\", y=[\"model_input_trips_old\", \"model_input_trips_new\"],figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d8da61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e653db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_df = pd.DataFrame(model_validity_stats)\n",
    "model_validity_df[[\"all_trip_count_old\", \"unlabeled_trip_count_old\", \"model_input_trips_old\", \"model_input_trips_new\", \"predicted_trips_all_old\", \"predicted_trips_unlabeled_old\", \"predicted_trips_all_new\", \"predicted_trips_unlabeled_new\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9220f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_validity_df.plot.bar(y=[\"all_trip_count_old\", \"predicted_trips_all_old\", \"predicted_trips_all_new\"], figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_df.plot.bar(y=[\"unlabeled_trip_count_old\", \"predicted_trips_unlabeled_old\", \"predicted_trips_unlabeled_new\"], figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_df[\"unlabeled_predict_pct_new\"] = model_validity_df.predicted_trips_unlabeled_new/model_validity_df.unlabeled_trip_count_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_df[\"unlabeled_predict_pct_old\"] = model_validity_df.predicted_trips_unlabeled_old/model_validity_df.unlabeled_trip_count_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a01e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_validity_df.plot(kind=\"bar\", y=[\"unlabeled_predict_pct_old\", \"unlabeled_predict_pct_new\"], figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ba02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.Figure(figsize=(10,5))\n",
    "axarr = fig.subplots(1,2)\n",
    "model_validity_df.plot(kind=\"scatter\", x=\"valid_trip_count_new\", y=\"unlabeled_predict_pct_old\", color=\"red\", ax=axarr[0])\n",
    "model_validity_df.plot(kind=\"scatter\", x=\"valid_trip_count_new\", y=\"unlabeled_predict_pct_new\", color=\"green\", ax=axarr[1])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede84e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_df.query(\"unlabeled_predict_pct_new < 0.2\")[[\"program\", \"valid_trip_count_new\", \"unlabeled_predict_pct_old\", \"unlabeled_predict_pct_new\"]].to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validity_df.query(\"unlabeled_predict_pct_new < 0.01\")[[\"program\", \"all_trip_count_new\", \"unlabeled_trip_count_new\", \"valid_trip_count_new\", \"unlabeled_predict_pct_old\", \"unlabeled_predict_pct_new\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f61f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
