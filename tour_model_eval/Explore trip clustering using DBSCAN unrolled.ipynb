{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finnish-despite",
   "metadata": {},
   "source": [
    "# Explore trip clustering using DBSCAN\n",
    "\n",
    "In `Radius Selection Unrolled`, we explored the options to select the radius based on distances around the start or end location. Can we also combine them to create a trip-level clustering that is an alternate, and much simpler implementation of the similarity code? Let's see if we can use DBSCAN to do this and whether the final trip counts are principled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-seventh",
   "metadata": {},
   "source": [
    "### First, we read the data and extract the most common purpose labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geojson as gj\n",
    "import sklearn.cluster as sc\n",
    "import sklearn.metrics.pairwise as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import branca.element as bre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from uuid import UUID\n",
    "\n",
    "import bson.json_util as bju\n",
    "import bson.objectid as boi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.decorations.trip_queries as esdtq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-stock",
   "metadata": {},
   "source": [
    "### Read data and setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = esta.TimeSeries.get_uuid_list()\n",
    "confirmed_trip_df_map = {}\n",
    "labeled_trip_df_map = {}\n",
    "expanded_trip_df_map = {}\n",
    "for u in all_users:\n",
    "    ts = esta.TimeSeries.get_time_series(u)\n",
    "    ct_df = ts.get_data_df(\"analysis/confirmed_trip\")\n",
    "    confirmed_trip_df_map[u] = ct_df\n",
    "    labeled_trip_df_map[u] = esdtq.filter_labeled_trips(ct_df)\n",
    "    expanded_trip_df_map[u] = esdtq.expand_userinputs(labeled_trip_df_map[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trips_df = pd.DataFrame([[u, len(confirmed_trip_df_map[u]), len(labeled_trip_df_map[u])] for u in all_users], columns=[\"user_id\", \"all_trips\", \"labeled_trips\"]); n_trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_user = n_trips_df[n_trips_df.labeled_trips == n_trips_df.labeled_trips.median()].user_id.iloc[0]; median_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_user_df = expanded_trip_df_map[median_user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_RADIUS = 500\n",
    "FINAL_POINT_DBSCAN = sc.DBSCAN(FINAL_RADIUS, min_samples=2, metric=\"precomputed\")\n",
    "FINAL_TRIP_DBSCAN = sc.DBSCAN(FINAL_RADIUS * 2, min_samples=2, metric=\"precomputed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-command",
   "metadata": {},
   "source": [
    "### Standard functions (currently copied over from other notebooks; should be refactored into a python file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc_df(loc_series):\n",
    "    loc_df = pd.DataFrame(loc_series.apply(lambda p: p[\"coordinates\"]).to_list(), columns=[\"longitude\", \"latitude\"])\n",
    "    # display.display(end_loc_df.head())\n",
    "    return loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(loc_df):\n",
    "    EARTH_RADIUS = 6371000\n",
    "    radians_lat_lon = np.radians(loc_df[[\"latitude\", \"longitude\"]])\n",
    "    dist_matrix_meters = pd.DataFrame(smp.haversine_distances(radians_lat_lon, radians_lat_lon) * 6371000)\n",
    "    return dist_matrix_meters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-salmon",
   "metadata": {},
   "source": [
    "### Approach 1: Recluster based on trip distance\n",
    "\n",
    "- We add the start and end distances to form a combined distance matrix.\n",
    "- We cluster with a radius that is twice what we had before\n",
    "\n",
    "One potential challenge is that we may have one end of the trip be a very close match and the other end be very far (e.g. 10, 900) and still have the trip as a whole fit within the distance threshold (1000).\n",
    "\n",
    "On the other hand, maybe that is OK - if both the start and the end match, then it must be a pretty good match, and maybe we can be a bit lax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_distance_matrix = get_distance_matrix(get_loc_df(median_user_df.start_loc))\n",
    "end_distance_matrix = get_distance_matrix(get_loc_df(median_user_df.end_loc))\n",
    "start_loc_model = copy.copy(FINAL_POINT_DBSCAN).fit(start_distance_matrix)\n",
    "end_loc_model = copy.copy(FINAL_POINT_DBSCAN).fit(end_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_loc_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_loc_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_user_df[\"start_loc_cluster\"] = start_loc_model.labels_\n",
    "median_user_df[\"end_loc_cluster\"] = end_loc_model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-differential",
   "metadata": {},
   "source": [
    "#### Try to calculate trip clusters by adding up the distances and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_distance_matrix = start_distance_matrix + end_distance_matrix\n",
    "trip_model = copy.copy(FINAL_TRIP_DBSCAN).fit(combined_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_user_df[\"trip_cluster_method1\"] = trip_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(median_user_df.trip_cluster_method1 != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(trip_model.labels_ != -1), len(trip_model.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-emerald",
   "metadata": {},
   "source": [
    "### Approach 2: Find trips whose start and end location are both in clusters\n",
    "\n",
    "- Find all combinations of start and end clusters\n",
    "- Retain only ones where both start and end are non-noisy\n",
    "- Group them to get a unique set of (start, end) tuples and treat them (represented by an index) as the cluster labels\n",
    "- For each (start,end) tuple assign the corresponding cluster label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_upper_bound = median_user_df.query(\"start_loc_cluster != -1 and end_loc_cluster != -1\"); len(quick_upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-empty",
   "metadata": {},
   "source": [
    "We just got a quick upper bound on the number of trips by this method. Note that we just know that both the start and end start in a cluster, we are not yet sure they start in **the same cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combos = median_user_df.groupby([\"start_loc_cluster\", \"end_loc_cluster\"])\n",
    "valid_combos = [p for p in all_combos.groups if p[0] != -1 and p[1] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(list(all_combos.groups)), len(valid_combos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(all_combos.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(all_combos.groups)[(-1,-1)], dict(all_combos.groups)[(2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combos_dict = dict(all_combos.groups)\n",
    "valid_combos_series = pd.Series(valid_combos)\n",
    "\n",
    "for g, idxlist in all_combos_dict.items():\n",
    "    print(g, idxlist)\n",
    "    match = valid_combos_series[valid_combos_series == g]\n",
    "    if len(match) == 0:\n",
    "        print(f\"invalid combo {g} found for entries {idxlist}, trip is not in a cluster\")\n",
    "        median_user_df.loc[idxlist, \"trip_cluster_method2\"] = -1\n",
    "    else:\n",
    "        print(f\"valid combo {g} found for entries {idxlist}, setting trip cluster to {match.index[0]}\")\n",
    "        median_user_df.loc[idxlist, \"trip_cluster_method2\"] = int(match.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_user_df[[\"trip_cluster_method1\", \"trip_cluster_method2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_df = median_user_df.query(\"(trip_cluster_method1 == -1 and trip_cluster_method2 != -1) or (trip_cluster_method1 != -1 and trip_cluster_method2 == -1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(median_user_df.trip_cluster_method1 == -1), np.count_nonzero(median_user_df.trip_cluster_method2 == -1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-token",
   "metadata": {},
   "source": [
    "There are actually *fewer* \"noise\" entries with method 2, so more clusters. let's do some additional validation.\n",
    "\n",
    "First, we just compare the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(median_user_df.trip_cluster_method1.unique()), len(median_user_df.trip_cluster_method2.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-wagner",
   "metadata": {},
   "source": [
    "Whoa! Method 1 seems to generate bigger clusters, which, of course, may be good or bad. Next, we check that for each trip cluster, the start and end clusters are the same. So we can verify that each cluster of trips is between the same start and end points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(median_user_df.groupby(\"trip_cluster_method1\").apply(lambda df: len(df.start_loc_cluster.unique()) == 1 and len(df.end_loc_cluster.unique()) == 1)), len(median_user_df.trip_cluster_method1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(median_user_df.groupby(\"trip_cluster_method2\").apply(lambda df: len(df.start_loc_cluster.unique()) == 1 and len(df.end_loc_cluster.unique()) == 1)), len(median_user_df.trip_cluster_method2.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-limit",
   "metadata": {},
   "source": [
    "Aha! This is a clear argument for using the second method. In both methods, the noisy trips are not classified, as we might expect. However, in method 1, multiple trip clusters don't actually have the same start and end points. In method 2, everything other than the noisy trips starts and ends in the same point (by definition). But the flip side is that we have a lot more (small) clusters, so we will need to ask the user more often."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-venture",
   "metadata": {},
   "source": [
    "### Given that we are going to use method 2, maybe we are done?\n",
    "\n",
    "Let's visualize a few trips to verify, both on a map and using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geojson_for_trip_cluster(exp_df):\n",
    "    print(len(cluster_trips))\n",
    "    # [[[X1, Y1], [X1, Y1]],\n",
    "    # [[X1, Y1], [X1, Y1]]]\n",
    "    clistarray = cluster_trips[[\"start_loc\", \"end_loc\"]].apply(\n",
    "                    lambda se: [p[\"coordinates\"] for p in se]).to_numpy().tolist()\n",
    "    print([len(clist) for clist in clistarray])\n",
    "    linestrings = [gj.LineString(coordinates=clist) for clist in clistarray]\n",
    "    purpose_locs = gj.FeatureCollection(cluster_trips.start_loc.to_list() +\n",
    "                                        cluster_trips.end_loc.to_list() +\n",
    "                                        linestrings)\n",
    "    return folium.features.GeoJson(purpose_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geojson_for_point_cluster(exp_df, loc_field, loc_cluster_field, cluster_label):\n",
    "    cluster_trips = exp_df[exp_df[loc_cluster_field] == cluster_label]\n",
    "    print(len(cluster_trips))\n",
    "    purpose_locs = gj.FeatureCollection(cluster_trips[loc_field].to_list())\n",
    "    return folium.features.GeoJson(purpose_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-springer",
   "metadata": {},
   "source": [
    "This user does have \"home\" as the most common purpose, but \"transit transfer\" and \"personal med\" are above \"work\". Let's start with focusing on home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-neutral",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = bre.Figure()\n",
    "fig.add_subplot(1,2,1).add_child(folium.Map().add_child(get_geojson_for_trip_cluster(median_user_df[median_user_df[\"trip_cluster_method1\"] == 0])))\n",
    "fig.add_subplot(1,2,2).add_child(folium.Map().add_child(get_geojson_for_trip_cluster(median_user_df[median_user_df[\"trip_cluster_method2\"] == 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-foundation",
   "metadata": {},
   "source": [
    "uh-oh, method1 was expected to be a bit bad, but method2 appears to be just as bad. While most of the trips are between two clear clusters, there are also some clear outliers, like the big vertical line. Let's visualize the start location clusters, both on a map and on a plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-village",
   "metadata": {},
   "source": [
    "#### Cluster 0 on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = bre.Figure()\n",
    "fig.add_subplot(1,2,1).add_child(folium.Map().add_child(get_geojson_for_point_cluster(median_user_df, \"start_loc\", \"start_loc_cluster\", 0)))\n",
    "fig.add_subplot(1,2,2).add_child(folium.Map().add_child(get_geojson_for_point_cluster(median_user_df, \"end_loc\", \"end_loc_cluster\", 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_method2_df = median_user_df[median_user_df.trip_cluster_method2 == 0]\n",
    "c0_start_distance_matrix = start_distance_matrix.loc[c0_method2_df.index, c0_method2_df.index]\n",
    "c0_start_distance_matrix[c0_start_distance_matrix > FINAL_RADIUS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-thanks",
   "metadata": {},
   "source": [
    "The distance matrix helps us see what happened. Filtering out only the distances > the radius, we see that there are some clear outliers, which are near each other, far from the other cluster, but one of the points is close enough to one of the outliers, and they get merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc_df_for_cluster(exp_df, loc_cluster_field, cluster_label, loc_field=\"end_loc\"):\n",
    "    # Reuse the same function to get the loc_df\n",
    "    cluster_trips = exp_df[exp_df[loc_cluster_field] == cluster_label]\n",
    "    return pd.concat([cluster_trips, pd.DataFrame(cluster_trips[loc_field].apply(lambda p: p[\"coordinates\"]).to_list(), columns=[\"longitude\", \"latitude\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20,5))\n",
    "axarr = fig.subplots(1,3,sharex=True,sharey=True)\n",
    "# end_loc_df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", color = end_loc_df[\"90%\"].apply(lambda c: colors[c]), ax=ax, colorbar=False)\n",
    "get_loc_df_for_cluster(median_user_df, \"start_loc_cluster\", 0, \"start_loc\").plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", ax=axarr[0])\n",
    "get_loc_df_for_cluster(median_user_df, \"start_loc_cluster\", 1, \"start_loc\").plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", ax=axarr[1])\n",
    "get_loc_df_for_cluster(median_user_df, \"start_loc_cluster\", 2, \"start_loc\").plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", ax=axarr[2])\n",
    "# end_loc_df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", c = \"95%\", cmap=get_colormap(end_loc_df[\"95%\"]), ax=ax, colorbar=False)\n",
    "# ax = fig.add_subplot(1,3,3)\n",
    "# end_loc_df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", c = \"99%\", cmap=get_colormap(end_loc_df[\"99%\"]), ax=ax, colorbar=False)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-tension",
   "metadata": {},
   "source": [
    "Judging from this, clusters 2 and 3 might give better results. Let's try to verify that before trying to figure out how to fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = bre.Figure()\n",
    "fig.add_subplot(1,2,1).add_child(folium.Map().add_child(get_geojson_for_trip_cluster(median_user_df[median_user_df[\"trip_cluster_method1\"] == 1])))\n",
    "fig.add_subplot(1,2,2).add_child(folium.Map().add_child(get_geojson_for_trip_cluster(median_user_df[median_user_df[\"trip_cluster_method2\"] == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = bre.Figure()\n",
    "fig.add_subplot(1,2,1).add_child(folium.Map().add_child(get_geojson_for_trip_cluster(median_user_df[median_user_df[\"trip_cluster_method1\"] == 2])))\n",
    "fig.add_subplot(1,2,2).add_child(folium.Map().add_child(get_geojson_for_trip_cluster(median_user_df[median_user_df[\"trip_cluster_method2\"] == 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-annual",
   "metadata": {},
   "source": [
    "So this is another good indication that method 2 is better than method 1. It looks like this problem has been asked but not answered on stackoverflow.\n",
    "\n",
    "https://stackoverflow.com/questions/48217127/distance-based-classification\n",
    "\n",
    "I can think of an approach to use repeated iterations of DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_df = median_user_df[median_user_df.trip_cluster_method2 == 1]\n",
    "c1_start_distance_matrix = start_distance_matrix.loc[c1_df.index, c1_df.index]\n",
    "c1_start_distance_matrix[c1_start_distance_matrix > FINAL_RADIUS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "[p for p in c0_method2_df.index if p not in start_loc_model.core_sample_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(start_loc_model.core_sample_indices_), len(np.unique(start_loc_model.labels_)), len(median_user_df.start_loc_cluster.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-imaging",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
