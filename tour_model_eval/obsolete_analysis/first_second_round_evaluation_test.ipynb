{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "convinced-cedar",
   "metadata": {},
   "source": [
    "### This notebook is to compare the results of scipy hierarchical clustering and sklearn KMeans clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-wholesale",
   "metadata": {},
   "source": [
    "We have 2 rounds of clustering. The first test only uses hierarchical clustering for 2 rounds of clustering. The second test adds KMeans clustering in the 2nd round, after running hierarchical custering. Since we cannot directly get the model from scipy hierarchical clustering, also, in sklearn, the associated AgglomerativeClustering method doesn't support separated fit() and predict() functions, we need to use a clustering algorithm like KMeans to build and save the model and use the saved model to predict labels for the new trip.\n",
    "The result of this notebook shows that adding KMeans doesn't change the result from scipy hierarchical clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-michael",
   "metadata": {},
   "source": [
    "We use user 1 from the mini-pilot program here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.core.get_database as edb\n",
    "import emission.analysis.modelling.tour_model.similarity as similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emission.analysis.modelling.tour_model.get_request_percentage as grp\n",
    "import emission.analysis.modelling.tour_model.get_scores as gs\n",
    "import emission.analysis.modelling.tour_model.label_processing as lp\n",
    "import emission.analysis.modelling.tour_model.get_users as gu\n",
    "import emission.analysis.modelling.tour_model.data_preprocessing as preprocess\n",
    "import emission.analysis.modelling.tour_model.evaluation_pipeline as ep\n",
    "import matplotlib.pyplot as plt\n",
    "import emission.analysis.modelling.tour_model.get_plot as plot\n",
    "import emission.core.common as ecc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',200)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_uuid_obj = list(edb.get_profile_db().find({\"install_group\": \"participant\"}, {\"user_id\": 1, \"_id\": 0}))\n",
    "all_users = [u[\"user_id\"] for u in participant_uuid_obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-novel",
   "metadata": {},
   "source": [
    "### using scipy hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(1):\n",
    "    user = all_users[a]\n",
    "    df = pd.DataFrame(columns=['user','user_id','percentage of 1st round','homogeneity socre of 1st round',\n",
    "                               'percentage of 2nd round','homogeneity socre of 2nd round','scores','lower boundary','distance percentage'])\n",
    "    trips = preprocess.read_data(user)\n",
    "    filter_trips = preprocess.filter_data(trips, radius)\n",
    "\n",
    "    # filter out users that don't have enough valid labeled trips\n",
    "    if not gu.valid_user(filter_trips, trips):\n",
    "        continue\n",
    "    tune_idx, test_idx = preprocess.split_data(filter_trips)\n",
    "\n",
    "    # choose tuning/test set to run the model\n",
    "    # this step will use KFold (5 splits) to split the data into different subsets\n",
    "    # - tune: tuning set\n",
    "    # - test: test set\n",
    "    # Here we user a bigger part of the data for testing and a smaller part for tuning\n",
    "    tune_data = preprocess.get_subdata(filter_trips, test_idx)\n",
    "    test_data = preprocess.get_subdata(filter_trips, tune_idx)\n",
    "    \n",
    "    # tune data\n",
    "    for j in range(len(tune_data)):\n",
    "        low, dist_pct = ep.tune(tune_data[j], radius, kmeans=False)\n",
    "        df.loc[j,'lower boundary']=low\n",
    "        df.loc[j,'distance percentage']=dist_pct\n",
    "\n",
    "    # testing\n",
    "    for k in range(len(test_data)):\n",
    "        low = df.loc[k,'lower boundary']\n",
    "        dist_pct = df.loc[k,'distance percentage']\n",
    "\n",
    "        homo_first, percentage_first, homo_second, percentage_second, scores = ep.test(test_data[k],radius,low,\n",
    "                                                                                    dist_pct,kmeans=False)\n",
    "        df.loc[k, 'percentage of 1st round'] = percentage_first\n",
    "        df.loc[k, 'homogeneity socre of 1st round'] = homo_first\n",
    "        df.loc[k, 'percentage of 2nd round'] = percentage_second\n",
    "        df.loc[k, 'homogeneity socre of 2nd round'] = homo_second\n",
    "        df.loc[k, 'scores'] = scores\n",
    "        df['user_id'] = user\n",
    "        df['user']='user'+str(a+1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-keyboard",
   "metadata": {},
   "source": [
    "### using kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(1):\n",
    "    user = all_users[a]\n",
    "    df1 = pd.DataFrame(columns=['user','user_id','percentage of 1st round','homogeneity socre of 1st round',\n",
    "                               'percentage of 2nd round','homogeneity socre of 2nd round','scores','lower boundary','distance percentage'])\n",
    "    trips = preprocess.read_data(user)\n",
    "    filter_trips = preprocess.filter_data(trips, radius)\n",
    "\n",
    "    # filter out users that don't have enough valid labeled trips\n",
    "    if not gu.valid_user(filter_trips, trips):\n",
    "        continue\n",
    "    tune_idx, test_idx = preprocess.split_data(filter_trips)\n",
    "\n",
    "    # choose tuning/test set to run the model\n",
    "    # this step will use KFold (5 splits) to split the data into different subsets\n",
    "    # - tune: tuning set\n",
    "    # - test: test set\n",
    "    # Here we user a bigger part of the data for testing and a smaller part for tuning\n",
    "    tune_data = preprocess.get_subdata(filter_trips, test_idx)\n",
    "    test_data = preprocess.get_subdata(filter_trips, tune_idx)\n",
    "    \n",
    "    # tune data\n",
    "    for j in range(len(tune_data)):\n",
    "        low, dist_pct = ep.tune(tune_data[j], radius, kmeans=False)\n",
    "        df1.loc[j,'lower boundary']=low\n",
    "        df1.loc[j,'distance percentage']=dist_pct\n",
    "\n",
    "    # testing\n",
    "    # for testing, we add kmeans to re-build the model. Kmeans is run after hierarchical clustering, \n",
    "    # passed in n_clusters as a parameter that comes from the result of hierarchical clustering.\n",
    "    for k in range(len(test_data)):\n",
    "        low = df1.loc[k,'lower boundary']\n",
    "        dist_pct = df1.loc[k,'distance percentage']\n",
    "\n",
    "        homo_first, percentage_first, homo_second, percentage_second, scores = ep.test(test_data[k],radius,low,\n",
    "                                                                                    dist_pct,kmeans=True)\n",
    "        df1.loc[k, 'percentage of 1st round'] = percentage_first\n",
    "        df1.loc[k, 'homogeneity socre of 1st round'] = homo_first\n",
    "        df1.loc[k, 'percentage of 2nd round'] = percentage_second\n",
    "        df1.loc[k, 'homogeneity socre of 2nd round'] = homo_second\n",
    "        df1.loc[k, 'scores'] = scores\n",
    "        df1['user_id'] = user\n",
    "        df1['user']='user'+str(a+1)\n",
    "df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
