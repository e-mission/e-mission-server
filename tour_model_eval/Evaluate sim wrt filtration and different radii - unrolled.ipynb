{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finnish-despite",
   "metadata": {},
   "source": [
    "# Evaluate the use of the similarity code for trip clustering\n",
    "\n",
    "In the `Explore sim usage (common trips -> labeling) unrolled` notebook, we determined some changes to the similarity settings to work better with our use case. We will now explore the impact of those changes, and of the radius parameter.\n",
    "\n",
    "Overall, we will experiment with three parameters:\n",
    "1. filter or not\n",
    "2. radius\n",
    "3. cutoff or not\n",
    "\n",
    "This notebook is intended to be run against the participant-only version of the CanBikeCO Jan 31 minipilot dataset.\n",
    "If you have the older version that includes data from non-participants as well, please replace\n",
    "\n",
    "```\n",
    "all_users = esta.TimeSeries.get_uuid_list()\n",
    "```\n",
    "\n",
    "with \n",
    "\n",
    "```\n",
    "participant_uuid_obj = list(edb.get_profile_db().find({\"install_group\": \"participant\"}, {\"user_id\": 1, \"_id\": 0}))\n",
    "all_users = [u[\"user_id\"] for u in participant_uuid_obj]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-seventh",
   "metadata": {},
   "source": [
    "### First, we read the data and extract the most common purpose labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geojson as gj\n",
    "import sklearn.cluster as sc\n",
    "import sklearn.metrics.pairwise as smp\n",
    "import sklearn.metrics as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import branca.element as bre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from uuid import UUID\n",
    "\n",
    "import bson.json_util as bju\n",
    "import bson.objectid as boi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.decorations.trip_queries as esdtq\n",
    "import emission.analysis.modelling.tour_model.similarity as eamts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.core.wrapper.entry as ecwe\n",
    "import emission.core.wrapper.confirmedtrip as ecwct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-webcam",
   "metadata": {},
   "source": [
    "### Read data and setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = esta.TimeSeries.get_uuid_list()\n",
    "confirmed_trip_df_map = {}\n",
    "labeled_trip_df_map = {}\n",
    "expanded_trip_df_map = {}\n",
    "for u in all_users:\n",
    "    ts = esta.TimeSeries.get_time_series(u)\n",
    "    ct_df = ts.get_data_df(\"analysis/confirmed_trip\")\n",
    "    confirmed_trip_df_map[u] = ct_df\n",
    "    labeled_trip_df_map[u] = esdtq.filter_labeled_trips(ct_df)\n",
    "    expanded_trip_df_map[u] = esdtq.expand_userinputs(labeled_trip_df_map[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS_CHOICES = [100, 300, 500]\n",
    "REGIME_CHOICES = [\"no_filter_no_cutoff\", \"no_filter_cutoff\", \"filter_no_cutoff\", \"filter_cutoff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_INPUT_COLS = [\"mode_confirm\", \"purpose_confirm\", \"replaced_mode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-modern",
   "metadata": {},
   "source": [
    "### Standard functions (currently copied over from other notebooks; should be refactored into a python file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc_df(loc_series):\n",
    "    loc_df = pd.DataFrame(loc_series.apply(lambda p: p[\"coordinates\"]).to_list(), columns=[\"longitude\", \"latitude\"])\n",
    "    # display.display(end_loc_df.head())\n",
    "    return loc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-standing",
   "metadata": {},
   "source": [
    "### First, we pick a participant to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trips_df = pd.DataFrame([[u, len(confirmed_trip_df_map[u]), len(labeled_trip_df_map[u])] for u in all_users], columns=[\"user_id\", \"all_trips\", \"labeled_trips\"]); n_trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_user = n_trips_df[n_trips_df.labeled_trips == n_trips_df.labeled_trips.median()].user_id.iloc[0]; median_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_user_df = expanded_trip_df_map[median_user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04578e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = median_user\n",
    "user_trip_df = median_user_df\n",
    "user_trip_list = [ecwe.Entry({\"data\": ecwct.Confirmedtrip(tr), \"_id\": tr[\"_id\"], \"metadata\": {\"key\": \"analysis/confirmed_trip\"}}) for tr in user_trip_df.to_dict(\"records\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_trip_clusters_oursim(participant_df.index[0], all_expanded_df)\n",
    "for r in RADIUS_CHOICES:\n",
    "    curr_sim = eamts.similarity(user_trip_list, r, shouldFilter=False, cutoff=False)\n",
    "    curr_sim.fit()\n",
    "    user_trip_df[f\"nofilter_nocutoff_{r}\"] = curr_sim.labels_\n",
    "    \n",
    "    curr_sim = eamts.similarity(user_trip_list, r, shouldFilter=False, cutoff=True)\n",
    "    curr_sim.fit()\n",
    "    user_trip_df[f\"nofilter_cutoff_{r}\"] = curr_sim.labels_\n",
    "    \n",
    "    curr_sim = eamts.similarity(user_trip_list, r, shouldFilter=True, cutoff=False)\n",
    "    curr_sim.fit()\n",
    "    user_trip_df[f\"filter_nocutoff_{r}\"] = curr_sim.labels_\n",
    "    \n",
    "    curr_sim = eamts.similarity(user_trip_list, r, shouldFilter=True, cutoff=True)\n",
    "    curr_sim.fit()\n",
    "    user_trip_df[f\"filter_cutoff_{r}\"] = curr_sim.labels_    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trip_df[[\"nofilter_nocutoff_100\", \"nofilter_cutoff_100\", \"filter_nocutoff_100\", \"filter_cutoff_100\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c9ba12",
   "metadata": {},
   "source": [
    "### Assign \"ground truth\" labels for either tuples or individual columns\n",
    "\n",
    "In order to get the ground truth labels, we need to find all unique combinations and assign labels based on that. I wonder if we can just send the n-tuple of the user labels directly. Probably better to do a conversion first. Conversion also lets us experiment with individual columns instead of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ground_truth(trip_df, columns, gt_label):\n",
    "    unique_tuples = dict(trip_df.groupby(by=columns).groups)\n",
    "    for i, idxlist in enumerate(unique_tuples.values()):\n",
    "    # print(i, idxlist)\n",
    "        trip_df.loc[idxlist, gt_label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ground_truth(user_trip_df, [\"mode_confirm\", \"purpose_confirm\", \"replaced_mode\"], \"ground_truth_tuple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b0211",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trip_df.ground_truth_tuple.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268504b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ground_truth(user_trip_df, [\"mode_confirm\"], \"ground_truth_mc\")\n",
    "add_ground_truth(user_trip_df, [\"purpose_confirm\"], \"ground_truth_pc\")\n",
    "add_ground_truth(user_trip_df, [\"replaced_mode\"], \"ground_truth_rm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ac0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trip_df.ground_truth_mc.max(), user_trip_df.ground_truth_pc.max(), user_trip_df.ground_truth_rm.max(), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52385e",
   "metadata": {},
   "source": [
    "### Let us now compute the homogeneity score and the request percentage in case of no cutoff\n",
    "\n",
    "- request %: the request % is just the number of clusters, since we will ask the user once for each cluster.\n",
    "- homogeneity score: we just use the built-in sklearn method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfnc = user_trip_df[\"nofilter_nocutoff_100\"].unique(); nfnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259556ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.homogeneity_score(user_trip_df.ground_truth_tuple, user_trip_df[\"nofilter_nocutoff_100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.homogeneity_score(user_trip_df.ground_truth_mc, user_trip_df[\"nofilter_nocutoff_100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6144df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.homogeneity_score(user_trip_df.ground_truth_pc, user_trip_df[\"nofilter_nocutoff_100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58407987",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.homogeneity_score(user_trip_df.ground_truth_rm, user_trip_df[\"nofilter_nocutoff_100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_trip_cluster_labels = [c for c in nfnc if np.count_nonzero(user_trip_df.nofilter_nocutoff_100 == c) > 1]; two_trip_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trip_df[user_trip_df.nofilter_nocutoff_100 == 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_trip_cluster_trips = user_trip_df[user_trip_df.nofilter_nocutoff_100.isin(two_trip_cluster_labels)]\n",
    "two_trip_cluster_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.homogeneity_score(two_trip_cluster_trips.ground_truth_tuple, two_trip_cluster_trips.nofilter_nocutoff_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nfnc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4308354c",
   "metadata": {},
   "source": [
    "### Let us now compute the homogeneity score and the request percentage in case of cutoff\n",
    "\n",
    "- request %: we will need to add the \"noisy\" trips (trips with labels of -1) since they will not be in clusters\n",
    "- homogeneity score: we just use the built-in sklearn method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfc = user_trip_df[\"nofilter_cutoff_100\"].unique(); nfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.homogeneity_score(user_trip_df.ground_truth_tuple, user_trip_df[\"nofilter_cutoff_100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nfc[nfc != -1]), np.count_nonzero(user_trip_df[\"nofilter_cutoff_100\"] == -1), len(nfc[nfc != -1]) + np.count_nonzero(user_trip_df[\"nofilter_cutoff_100\"] == -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f8e120",
   "metadata": {},
   "source": [
    "### Let us now compute the homogeneity score and the request percentage with filtering\n",
    "\n",
    "- request %: we will need to add the filtered trips (trips with labels of -2) since they will not be in clusters\n",
    "- homogeneity score: we just use the built-in sklearn method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = user_trip_df[\"filter_cutoff_100\"].unique(); fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a81dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.homogeneity_score(user_trip_df.ground_truth_tuple, user_trip_df[\"filter_cutoff_100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54faf262",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.count_nonzero(fc >= 0),\n",
    "np.count_nonzero(user_trip_df[\"filter_cutoff_100\"].unique() >= 0),\n",
    "np.count_nonzero(user_trip_df[\"filter_cutoff_100\"] == -1),\n",
    "np.count_nonzero(user_trip_df[\"filter_cutoff_100\"] == -2), \n",
    "np.count_nonzero(fc >= 0) + np.count_nonzero(user_trip_df[\"filter_cutoff_100\"] == -1) + np.count_nonzero(user_trip_df[\"filter_cutoff_100\"] == -2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364c38f",
   "metadata": {},
   "source": [
    "### Let us compare the cluster : trip ratio with the request %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_trip_df.nofilter_nocutoff_300.unique()), len(user_trip_df.nofilter_nocutoff_300.unique())/len(user_trip_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2658a8",
   "metadata": {},
   "source": [
    "## Generalizing to multiple users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458197d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_ground_truth_cols(trip_df):\n",
    "    add_ground_truth(trip_df, [\"mode_confirm\", \"purpose_confirm\", \"replaced_mode\"], \"ground_truth_tuple\")\n",
    "    add_ground_truth(trip_df, [\"mode_confirm\"], \"ground_truth_mc\")\n",
    "    add_ground_truth(trip_df, [\"purpose_confirm\"], \"ground_truth_pc\")\n",
    "    add_ground_truth(trip_df, [\"replaced_mode\"], \"ground_truth_rm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaeb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predicted_cols(trip_df):\n",
    "    trip_list = [ecwe.Entry({\"data\": ecwct.Confirmedtrip(tr), \"_id\": tr[\"_id\"], \"metadata\": {\"key\": \"analysis/confirmed_trip\"}}) for tr in trip_df.to_dict(\"records\")]\n",
    "    for r in RADIUS_CHOICES:\n",
    "        curr_sim = eamts.similarity(trip_list, r, shouldFilter=False, cutoff=False)\n",
    "        curr_sim.fit()\n",
    "        trip_df[f\"no_filter_no_cutoff_{r}\"] = curr_sim.labels_.to_list()\n",
    "        # print(f\"Got labels {curr_sim.labels_} of length {len(curr_sim.labels_.dropna())}\")\n",
    "\n",
    "        curr_sim = eamts.similarity(trip_list, r, shouldFilter=False, cutoff=True)\n",
    "        curr_sim.fit()\n",
    "        trip_df[f\"no_filter_cutoff_{r}\"] = curr_sim.labels_.to_list()\n",
    "\n",
    "        curr_sim = eamts.similarity(trip_list, r, shouldFilter=True, cutoff=False)\n",
    "        curr_sim.fit()\n",
    "        trip_df[f\"filter_no_cutoff_{r}\"] = curr_sim.labels_.to_list()\n",
    "\n",
    "        curr_sim = eamts.similarity(trip_list, r, shouldFilter=True, cutoff=True)\n",
    "        curr_sim.fit()\n",
    "        trip_df[f\"filter_cutoff_{r}\"] = curr_sim.labels_.to_list()\n",
    "    print(f\"For {trip_df.user_id.iloc[0]}, returning df with cols {trip_df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8a7b4",
   "metadata": {},
   "source": [
    "Some subset of the user labels may be missing, in which case it will be represented by NaN\n",
    "This won't match any unique values, so the ground truth will be NaN and the score calculation will break.\n",
    "We can try to `dropna()` but if the other values are present, it doesn't make sense to drop the entire trip from\n",
    "similarity modeling. Let's do a separate check instead.\n",
    "\n",
    "```\n",
    "mode_confirm \tpurpose_confirm \treplaced_mode \tground_truth_rm\n",
    "64 \tdrove_alone \tschool \tNaN \tNaN\n",
    "71 \tdrove_alone \twork \tNaN \tNaN\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_score_no_na(labels_true, labels_pred):\n",
    "    na_index = labels_true[pd.isna(labels_true)].index\n",
    "    # Before we set the index to nan; we don't want to have a side effect here!\n",
    "    new_labels_true = labels_true.copy()\n",
    "    new_labels_pred = labels_pred.copy()\n",
    "    new_labels_pred.loc[na_index] = np.nan\n",
    "    if (len(na_index) > 0):\n",
    "        print(f\"Dropping nan indices {na_index} before calculating score\")\n",
    "        # print(f\"{labels_true.dropna()}, {new_labels_pred.dropna()}\")\n",
    "    return sm.homogeneity_score(new_labels_true.dropna(), new_labels_pred.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dacd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_count(labels_pred):\n",
    "    # once per real cluster\n",
    "    # once per noisy point (since it is not in a cluster)\n",
    "    # once per filtered trip (not really necessary for our current regime, but good to be prepared)\n",
    "    return np.count_nonzero(labels_pred.unique() >= 0) \\\n",
    "                    + np.count_nonzero(labels_pred == -1) \\\n",
    "                    + np.count_nonzero(labels_pred == -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9345322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics(trip_df):\n",
    "    curr_result = {\"n_trips\": len(trip_df)}\n",
    "    curr_result[\"ground_truth_tuple_unique\"] = trip_df.ground_truth_tuple.unique()\n",
    "    curr_result[\"ground_truth_mode_unique\"] = trip_df.ground_truth_mc.unique()\n",
    "    curr_result[\"ground_truth_purpose_unique\"] = trip_df.ground_truth_pc.unique()\n",
    "    curr_result[\"ground_truth_replaced_mode_unique\"] = trip_df.ground_truth_rm.unique()\n",
    "\n",
    "    curr_result[\"ground_truth_tuple_lower_bound\"] = len(trip_df.ground_truth_tuple.unique())\n",
    "    curr_result[\"ground_truth_mode_lower_bound\"] = len(trip_df.ground_truth_mc.unique())\n",
    "    curr_result[\"ground_truth_purpose_lower_bound\"] = len(trip_df.ground_truth_pc.unique())\n",
    "    curr_result[\"ground_truth_replaced_mode_lower_bound\"] = len(trip_df.ground_truth_rm.unique())\n",
    "\n",
    "    # print(f\"after computing lower bounds: {curr_result}\")\n",
    "    for r in RADIUS_CHOICES:\n",
    "        for regime in [\"no_filter_no_cutoff\", \"no_filter_cutoff\", \"filter_no_cutoff\", \"filter_cutoff\"]:\n",
    "            for gts in [\"tuple\", \"mc\", \"pc\", \"rm\"]:\n",
    "                print(f\"About to calculate score by comparing {trip_df[f'ground_truth_{gts}'].unique()} for ground_truth_{gts} with {trip_df[f'{regime}_{r}'].unique()}\")\n",
    "                curr_result[f\"{regime}_{r}_homogeneity_score_{gts}\"] = \\\n",
    "                    h_score_no_na(trip_df[f\"ground_truth_{gts}\"], trip_df[f\"{regime}_{r}\"])\n",
    "            # request pct doesn't depend on ground truth, only on the predicted clustering\n",
    "            curr_result[f\"{regime}_{r}_request_count\"] = request_count(user_trip_df[f\"{regime}_{r}\"])\n",
    "            curr_result[f\"{regime}_{r}_request_pct\"] = curr_result[f\"{regime}_{r}_request_count\"] / curr_result[\"n_trips\"]\n",
    "            curr_result[f\"{regime}_{r}_cluster_trip_ratio\"] = len(curr_trip_df[f\"{regime}_{r}\"].unique()) / curr_result[\"n_trips\"]\n",
    "            \n",
    "\n",
    "    # print(f\"For {trip_df.user_id.iloc[0]}, returning result {curr_result}\")\n",
    "    return curr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370213ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_trip_df = expanded_trip_df_map[UUID(\"576e37c7-ab7e-4c03-add7-02486bc3f42e\")]\n",
    "# test_trip_df[\"no_filter_no_cutoff_100\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume at least two trip per day (to/from work?!) forexpanded_trip_df_mapweek\n",
    "valid_users = [u for u in all_users if len(expanded_trip_df_map[u]) > 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184989c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **NOTE**: this cell will take a long time to execute\n",
    "# Splitting this out from the result map generation to make it easier to generate different lists\n",
    "for user_id in valid_users:\n",
    "    print(f\"Computing results for user {user_id}\")\n",
    "    curr_trip_df = expanded_trip_df_map[user_id]\n",
    "    # May be needed because the input dataframe may not have contiguous indices (e.g. since we have filtered it to only trips with user labels\n",
    "    # However, not sure how that will work in the overall DF where we have all the trips in one giant dataframe\n",
    "    # so let us avoid for now\n",
    "    # curr_trip_df.reset_index(inplace=True)\n",
    "    all_ground_truth_cols(curr_trip_df)\n",
    "    add_predicted_cols(curr_trip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_result_list = []\n",
    "for user_id in valid_users:\n",
    "    print(f\"Computing results for user {user_id}\")\n",
    "    curr_trip_df = expanded_trip_df_map[user_id]\n",
    "    curr_metrics = get_all_metrics(curr_trip_df)\n",
    "    curr_metrics[\"user_id\"] = user_id\n",
    "    standard_result_list.append(curr_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2674b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(standard_result_list); result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e671def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147ad74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb090a1",
   "metadata": {},
   "source": [
    "## Basic comparisons of the homogeneity score v/s request pct tradeoffs for different regimes and radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f89ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use\n",
    "fig = plt.Figure(figsize=(20,5))\n",
    "axarr = fig.subplots(1,3)\n",
    "colors = plt.get_cmap(\"Accent\", 4).colors\n",
    "\n",
    "for i, r in enumerate(RADIUS_CHOICES):\n",
    "    ax = axarr[i]\n",
    "    # ax = result_df.plot.scatter(x=f\"no_filter_no_cutoff_{r}_homogeneity_score_tuple\", y=f\"no_filter_no_cutoff_{r}_request_pct\", label=f\"no_filter_no_cutoff_{r}\")\n",
    "    for j, regime in enumerate([\"no_filter_no_cutoff\", \"no_filter_cutoff\", \"filter_no_cutoff\", \"filter_cutoff\"]):\n",
    "        result_df.plot.scatter(x=f\"{regime}_{r}_homogeneity_score_tuple\", y=f\"{regime}_{r}_request_pct\", color=colors[j], label=f\"{regime}_{r}\", ax=ax)\n",
    "    ax.set_xlabel(\"homogeneity score\")\n",
    "    ax.set_ylabel(\"request pct\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e4ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20,5))\n",
    "axarr = fig.subplots(1,3)\n",
    "for i, r in enumerate(RADIUS_CHOICES):\n",
    "    result_df.boxplot(column=[f\"{regime}_{r}_request_pct\" for regime in REGIME_CHOICES], ax=axarr[i])\n",
    "    axarr[i].set_xticklabels(REGIME_CHOICES)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7801f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.boxplot(column=[\"no_filter_no_cutoff_500_request_pct\", \"no_filter_no_cutoff_500_cluster_trip_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37303728",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20,5))\n",
    "axarr = fig.subplots(1,3)\n",
    "for i, r in enumerate(RADIUS_CHOICES):\n",
    "    result_df.boxplot(column=[f\"{regime}_{r}_homogeneity_score_tuple\" for regime in REGIME_CHOICES], ax=axarr[i])\n",
    "    axarr[i].set_xticklabels(REGIME_CHOICES)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151dad9",
   "metadata": {},
   "source": [
    "There is a very clear difference between no_cutoff and cutoff. The cutoff results are significantly worse wrt their homogeneity scores, which are clearly being propped up by the single trip clusters. There is not a significant difference between the various radii.\n",
    "\n",
    "These values are worse than the cluster:trip ratio that we found in the full dataset. But the no_filter_no_cluster cases should be almost the same! Let's compute the cluster:trip ratio and confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in RADIUS_CHOICES:\n",
    "#     for regime in [\"no_filter_no_cutoff\", \"no_filter_cutoff\", \"filter_no_cutoff\", \"filter_cutoff\"]:\n",
    "#         result_df[f\"{regime}_{r}_cluster_trip_ratio\"] = result_df.user_id.apply(lambda u: len(expanded_trip_df_map[u][f\"{regime}_{r}\"].unique())) / result_df[\"n_trips\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1da1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20,5))\n",
    "axarr = fig.subplots(1,3)\n",
    "colors = plt.get_cmap(\"Accent\", 4).colors\n",
    "\n",
    "for i, r in enumerate(RADIUS_CHOICES):\n",
    "    ax = axarr[i]\n",
    "    # ax = result_df.plot.scatter(x=f\"no_filter_no_cutoff_{r}_homogeneity_score_tuple\", y=f\"no_filter_no_cutoff_{r}_request_pct\", label=f\"no_filter_no_cutoff_{r}\")\n",
    "    for j, regime in enumerate([\"no_filter_no_cutoff\", \"no_filter_cutoff\", \"filter_no_cutoff\", \"filter_cutoff\"]):\n",
    "        result_df.plot.scatter(x=f\"{regime}_{r}_request_pct\", y=f\"{regime}_{r}_cluster_trip_ratio\", color=colors[j], label=f\"{regime}_{r}\", ax=ax)\n",
    "    ax.set_xlabel(\"request pct\")\n",
    "    ax.set_ylabel(\"cluster trip ratio\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20360247",
   "metadata": {},
   "source": [
    "As we can see, the no_filter_no_cutoff results are pretty much identical to the cluster_trip_ratio, which is not surprising because in that regime, we include all trips, and all bins. But even the no_filter_no_cluster 500m ratio (median > ~0.6, max 0.85) is worse than the DBSCAN results (median < 0.4, max ~ 0.7).\n",
    "\n",
    "On the other hand, the sim v/s DBSCAN comparion indicates that DBSCAN can have weird results sometimes, specially for the triangular trips. Let's stick with binning for now, but keep DBSCAN as an option for later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b457e",
   "metadata": {},
   "source": [
    "## Selected radius: 500, selected regime: no filter, no cutoff\n",
    "\n",
    "Based on the tradeoff results so far, the radius = 500 + no filter, no cutoff is clearly the way to go.\n",
    "It has the lowest request % and highest homogeneity score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97350eec",
   "metadata": {},
   "source": [
    "## Pick correct metrics\n",
    "\n",
    "### Fix the h-score calculation\n",
    "\n",
    "While looking at the comparison between the DBSCAN algorithm and the similarity code, I noticed that the homogeneity score was significantly lower for DBSCAN, which was surprising. On reflection, I realized that this was because the noisy trips were all being put into one cluster instead of multiple clusters.\n",
    "\n",
    "For example, consider the case in which we have two clusters of length 2 each, and 4 single trip clusters.\n",
    "\n",
    "If all the single trip clusters are labeled with -1 for noise, we will end up with\n",
    "\n",
    "```\n",
    ">>> sm.homogeneity_score([1,1,2,2,3,4,5,6], [0,0,1,1,-1,-1,-1,-1])\n",
    "0.5999999999999999\n",
    "```\n",
    "\n",
    "because it looks like the -1 predicted cluster actually munges entries from 4 different ground truth clusters.\n",
    "If we replace them with unique cluster labels, we get a perfect score, as expected.\n",
    "\n",
    "```\n",
    ">>> sm.homogeneity_score([1,1,2,2,3,4,5,6], [0,0,1,1,2,3,4,5])\n",
    "1.0\n",
    "```\n",
    "\n",
    "\n",
    "We can and should fix this, but this leads me to wonder whether we are in fact picking the correct metrics. Because once we replace the noisy points with unique labels, the non-cutoff and cutoff results will pretty much be identical (unless there are clusters with size > 1 which are cutoff, which seems unlikely). And the request % will be identical since we will ask the user once for each single trip cluster (whether retained or cutoff as noisy).\n",
    "\n",
    "The main reasons why these are identical is because the distributions appear to be long-tailed, so the cutoff step basically only deletes 1 trip clusters. If this were not true, there would actually be a difference in the noisy trips between the two approaches and a difference in the results.\n",
    "\n",
    "However, the choice of cutting off **can potentially** affect the modeling. If 50% of the trips are below the cutoff (as we saw in the similarity deep dive, we have a much smaller pool of entries to work with. And if one of the test entries does in fact match the 50% of the trips that are deleted, we won't have to ask the user.\n",
    "\n",
    "To capture this, we need to build a model with or without the cutoff and match **something else** to model. That will give us an idea of whether those infrequent trips really do matter when matching with trips not in the model.\n",
    "\n",
    "I can think of two options for **something else**.\n",
    "- Split the data: we should check the performance with both a large model and small data (state for each iteration) and a small model and large data (state overall/when we reset the pipeline).\n",
    "- Use the unlabeled data: while the unlabeled data doesn't have labels, it certainly has start and end points. We should be able to \n",
    "\n",
    "\n",
    "So it seems like the homogeneity score is a property of the model (which makes sense since it requires labeled data), and the request pct can/should be a property of the **unlabeled data** tested against that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_score_no_na(expanded_trip_df_map[all_users[0]].no_filter_no_cutoff_100, expanded_trip_df_map[all_users[0]].no_filter_cutoff_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0e74b",
   "metadata": {},
   "source": [
    "## Experiment with a new version of the function that treats trips below cutoff as single trip clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimplemented version\n",
    "def h_score_no_na(labels_true, labels_pred):\n",
    "    na_index = labels_true[pd.isna(labels_true)].index\n",
    "    pred_noise_index = labels_pred[labels_pred < 0].index\n",
    "    # Copy before we set the index to nan; we don't want to have a side effect here!\n",
    "    new_labels_true = labels_true.copy()\n",
    "    new_labels_pred = labels_pred.copy()\n",
    "    # Create a set of unique clusters for the noisy trips\n",
    "    new_labels_pred.loc[pred_noise_index] = range(len(pred_noise_index))\n",
    "    # Set all the indices corresponding to NaN in the ground truth to NaN in the pred\n",
    "    # Note that we want to do this **after** replacing noisy trips\n",
    "    # Since otherwise, if label_true = NaN and label_pred = -1,\n",
    "    # we would end up with a unique cluster\n",
    "    new_labels_pred.loc[na_index] = np.nan\n",
    "    if (len(na_index) > 0):\n",
    "        print(f\"Dropping nan indices {na_index} before calculating score\")\n",
    "        # print(f\"{labels_true.dropna()}, {new_labels_pred.dropna()}\")\n",
    "    return sm.homogeneity_score(new_labels_true.dropna(), new_labels_pred.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96edb5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_score_no_na(expanded_trip_df_map[all_users[0]].no_filter_no_cutoff_100, expanded_trip_df_map[all_users[0]].no_filter_cutoff_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcabb5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should use the new version of the function\n",
    "# We are OK with this weird format where we change the function implementation because\n",
    "# it is an unrolled notebook\n",
    "standard_result_list = []\n",
    "for user_id in valid_users:\n",
    "    print(f\"Computing results for user {user_id}\")\n",
    "    curr_trip_df = expanded_trip_df_map[user_id]\n",
    "    curr_metrics = get_all_metrics(curr_trip_df)\n",
    "    curr_metrics[\"user_id\"] = user_id\n",
    "    standard_result_list.append(curr_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(standard_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d32277",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20,5))\n",
    "axarr = fig.subplots(1,3)\n",
    "for i, r in enumerate(RADIUS_CHOICES):\n",
    "    result_df.boxplot(column=[f\"{regime}_{r}_homogeneity_score_tuple\" for regime in REGIME_CHOICES], ax=axarr[i])\n",
    "    axarr[i].set_xticklabels(REGIME_CHOICES)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70246c84",
   "metadata": {},
   "source": [
    "## Experiment with a new version of the function that drops trips below cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed870fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimplemented version\n",
    "def h_score_no_na(labels_true, labels_pred):\n",
    "    pred_noise_index = labels_pred[labels_pred < 0].index\n",
    "    # Copy before we set the index to nan; we don't want to have a side effect here!\n",
    "    new_labels_true = labels_true.copy()\n",
    "    new_labels_pred = labels_pred.copy()\n",
    "    \n",
    "    # print(f\"Before dropping labels without noise {new_labels_true}, {new_labels_pred}\")\n",
    "    # print(f\"Dropping labels without noise {pred_noise_index}\")\n",
    "    # only retain labels from non-noisy trips\n",
    "    new_labels_true.drop(pred_noise_index, inplace=True)\n",
    "    new_labels_pred.drop(pred_noise_index, inplace=True)\n",
    "    \n",
    "    # print(f\"After dropping labels without noise {new_labels_true}, {new_labels_pred}\")\n",
    "    \n",
    "    # Set all the indices corresponding to NaN in the ground truth to NaN in the pred\n",
    "    # Note that is it probably best to do this *after** dropping noisy trips\n",
    "    # Since, if label_true = NaN and label_pred = -1,\n",
    "    # we would have dropped it anyway\n",
    "    na_index = new_labels_true[pd.isna(labels_true)].index\n",
    "    new_labels_pred.loc[na_index] = np.nan\n",
    "    if (len(na_index) > 0):\n",
    "        print(f\"Dropping nan indices {na_index} before calculating score\")\n",
    "        # print(f\"{labels_true.dropna()}, {new_labels_pred.dropna()}\")\n",
    "    return sm.homogeneity_score(new_labels_true.dropna(), new_labels_pred.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6767d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should use the new version of the function\n",
    "# We are OK with this weird format where we change the function implementation because\n",
    "# it is an unrolled notebook\n",
    "standard_result_list = []\n",
    "for user_id in valid_users:\n",
    "    print(f\"Computing results for user {user_id}\")\n",
    "    curr_trip_df = expanded_trip_df_map[user_id]\n",
    "    curr_metrics = get_all_metrics(curr_trip_df)\n",
    "    curr_metrics[\"user_id\"] = user_id\n",
    "    standard_result_list.append(curr_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa23a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(standard_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20,5))\n",
    "axarr = fig.subplots(1,3)\n",
    "for i, r in enumerate(RADIUS_CHOICES):\n",
    "    result_df.boxplot(column=[f\"{regime}_{r}_homogeneity_score_tuple\" for regime in REGIME_CHOICES], ax=axarr[i])\n",
    "    axarr[i].set_xticklabels(REGIME_CHOICES)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace79d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
