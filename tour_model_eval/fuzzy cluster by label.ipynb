{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this notebook, I explore the idea of clustering by label (i.e. iterate over each label and create homogeneous clusters.) This yields overlapping clusters, hence the notebook name \"fuzzy cluster\" (I need to find a better term though). \n",
                "\n",
                "Work in progress - the clustering algorithm is implemented. Next step is to figure out how to make predictions with them. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from uuid import UUID\n",
                "\n",
                "# hack because jupyter notebook doesn't work properly through my vscode for\n",
                "# some reason and therefore cant import stuff from emission? remove this before\n",
                "# pushing\n",
                "###\n",
                "import sys\n",
                "\n",
                "sys.path.append('/Users/hlu2/Documents/GitHub/e-mission-server/')\n",
                "###\n",
                "\n",
                "import emission.storage.timeseries.abstract_timeseries as esta\n",
                "import emission.storage.decorations.trip_queries as esdtq\n",
                "import emission.core.get_database as edb\n",
                "import mapping"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### load data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# to see the same outputs I described, put in the unique tokens for these users\n",
                "email0 = \"replace this\"  # shankari\n",
                "email1 = \"replace this\"  # tom\n",
                "user0 = list(edb.get_uuid_db().find({\"user_email\": email0}))[0]['uuid']\n",
                "user1 = list(edb.get_uuid_db().find({\"user_email\": email1}))[0]['uuid']\n",
                "user2 = UUID('replace this')  # hannah\n",
                "\n",
                "all_users = esta.TimeSeries.get_uuid_list()\n",
                "user_list = np.append([user0, user1, user2],\n",
                "                      np.random.choice(all_users, size=10, replace=False))\n",
                "confirmed_trip_df_map = {}\n",
                "labeled_trip_df_map = {}\n",
                "expanded_labeled_trip_df_map = {}\n",
                "expanded_all_trip_df_map = {}\n",
                "for i in range(len(user_list)):\n",
                "    u = user_list[i]\n",
                "    print(u)\n",
                "    ts = esta.TimeSeries.get_time_series(u)\n",
                "    ct_df = ts.get_data_df(\"analysis/confirmed_trip\")\n",
                "\n",
                "    confirmed_trip_df_map[i] = ct_df\n",
                "    labeled_trip_df_map[i] = esdtq.filter_labeled_trips(ct_df)\n",
                "    expanded_labeled_trip_df_map[i] = esdtq.expand_userinputs(\n",
                "        labeled_trip_df_map[i])\n",
                "    expanded_all_trip_df_map[i] = esdtq.expand_userinputs(\n",
                "        confirmed_trip_df_map[i])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### clustering by label"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "process: \n",
                "- iterate over each label\n",
                "- - for each label, find clusters\n",
                "- - - use dbscan to identify density cores \n",
                "- now plot all clusters, see if there are any overlaps "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# quick test to make sure pipeline is working\n",
                "\n",
                "fig = mapping.plot_clusters(expanded_labeled_trip_df_map[0],\n",
                "                    alg='fuzzy',\n",
                "                    loc_type='end',\n",
                "                    cluster_unlabeled=False,\n",
                "                    plot_unlabeled=True,\n",
                "                    radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ok, cool, this is what I wanted. Now we have to figure out how to turn these fuzzy clusters into predictions. The nice thing about clustering by label is that raising the DBSCAN radius doesn't dramatically raise the max cluster diameter because we've pretty much eliminated any dendrites that can form between two clusters of different labels. The only time when we might have an undesirably large cluster is if we get a dendrite between 2 nearby clusters with the same purpose. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_labeled_trip_df_map[2],\n",
                "                    alg='fuzzy',\n",
                "                    loc_type='end',\n",
                "                    cluster_unlabeled=False,\n",
                "                    plot_unlabeled=True,\n",
                "                    radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_labeled_trip_df_map[1],\n",
                "                    alg='fuzzy',\n",
                "                    loc_type='end',\n",
                "                    cluster_unlabeled=False,\n",
                "                    plot_unlabeled=True,\n",
                "                    radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "39792147defedce75a7e3a68ae8b893956023a509c7f6b059d8d59165c20ef2c"
        },
        "kernelspec": {
            "display_name": "Python 3.7.12",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
