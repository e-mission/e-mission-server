{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook explores the selection of different radii for the clustering of start and end points. This is a follow-up to `radius selection exploration unrolled` and aims to address the issue of clusters being too large and merging together smaller, unrelated clusters. \n",
                "\n",
                "The error for start-of-trip detection may be greater than for end-of-trip detection as the former is a more difficult task than the latter - thus, by separating the radii for start vs end clustering, we hope to make the end clusters tighter and produce better predictions. This notebook explores hardcoding values for the radius parameter, based on the distances between distinct locations in the real world. For reference, American city blocks tend to be ~100-200m. The current radius of 500m was set in order to handle noise from start-of-trip detection. However, that was quite large, and for example, can end up clustering destinations on opposite sides of a highway."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from uuid import UUID\n",
                "\n",
                "###\n",
                "# hack because jupyter notebook doesn't work properly through my vscode for\n",
                "# some reason and therefore cant import stuff from emission? TODO remove this # before any pull requests\n",
                "import sys\n",
                "\n",
                "sys.path.append('/Users/hlu2/Documents/GitHub/e-mission-server/')\n",
                "###\n",
                "\n",
                "import emission.storage.timeseries.abstract_timeseries as esta\n",
                "import emission.storage.decorations.trip_queries as esdtq\n",
                "import emission.core.get_database as edb\n",
                "\n",
                "import mapping"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### load data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# to see the same outputs I described, put in the unique tokens for these users\n",
                "email0 = \"replace this\"  # shankari\n",
                "email1 = \"replace this\"  # tom\n",
                "user0 = list(edb.get_uuid_db().find({\"user_email\": email0}))[0]['uuid']\n",
                "user1 = list(edb.get_uuid_db().find({\"user_email\": email1}))[0]['uuid']\n",
                "user2 = UUID('replace this')  # hannah\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_users = esta.TimeSeries.get_uuid_list()\n",
                "user_list = np.append([user0, user1, user2, user0],\n",
                "                      np.random.choice(all_users, size=10, replace=False))\n",
                "confirmed_trip_df_map = {}\n",
                "labeled_trip_df_map = {}\n",
                "expanded_trip_df_map = {}\n",
                "for i in range(len(user_list)):\n",
                "    u = user_list[i]\n",
                "    print(u)\n",
                "    ts = esta.TimeSeries.get_time_series(u)\n",
                "    ct_df = ts.get_data_df(\"analysis/confirmed_trip\")\n",
                "\n",
                "    # shuffle user0's data to see if the order in which oursim sees trips\n",
                "    # affects the binning results\n",
                "    if i == 3:\n",
                "        ct_df = ct_df.sample(frac=1).reset_index(drop=True)\n",
                "    confirmed_trip_df_map[i] = ct_df\n",
                "    labeled_trip_df_map[i] = esdtq.filter_labeled_trips(ct_df)\n",
                "    expanded_trip_df_map[i] = esdtq.expand_userinputs(labeled_trip_df_map[i])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check trip counts\n",
                "n_trips_df = pd.DataFrame([[\n",
                "    user_list[i],\n",
                "    len(confirmed_trip_df_map[i]),\n",
                "    len(labeled_trip_df_map[i])\n",
                "] for i in range(len(user_list))],\n",
                "                          columns=[\"user_id\", \"all_trips\", \"labeled_trips\"])\n",
                "n_trips_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check trip counts by purpose for user0\n",
                "expanded_trip_df_map[0].purpose_confirm.value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### playing with radius selection - end points only"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's see the clusters of end points for user0 using DBSCAN at a variety of radii. \n",
                "\n",
                "The plot_clusters() function will plot points and clusters on a folium map, which will provide us with a sense of scale and allow us to intuitively check if a cluster looks 'good'. Points with the same purpose will have the same color (unless there are more purposes than available colors in folium, in which case some colors may be duplicated). Hovering over a point will also reveal the purpose in the tooltip. The clusters are visualized as convex hulls; their color doesn't mean anything right now, it's simply so we can distinguish between distinct clusters (which will be helpful when there are overlapping clusters). "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[0],\n",
                "                            alg='DBSCAN',\n",
                "                            loc_type='end',\n",
                "                            plot_unlabeled=True,\n",
                "                            cluster_unlabeled=False,\n",
                "                            radii=[50, 100, 150, 200, 500])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "With a 100m radius, DBSCAN is able to distinguish between the 'home', 'library', and 'shopping' clusters that are all very close to each other (each 2-4 blocks away from each other). Once we increase the radius to 150m, the 'library' and 'shopping' clusters get combined. \n",
                "\n",
                "One issue with DBSCAN is that as we get more and more data, we risk getting more and more noisy points (for example, a point right in between the library and shopping clusters). The noisy point may then form a 'dendrite'/bridge, causing two distinct locations to merge into a single cluster. If we use DBSCAN, perhaps a naive correction would be to vary the radius according to user dataset size? Alternatively, we should explore using user labels to inform cluster size. This is also why I'm interested in a clustering function with dynamic scanning radius, which would hopefully be able to identify sparse noise between two dense but nearby clusters.\n",
                "\n",
                "Let's see how oursim performs:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[0],\n",
                "                            alg='oursim',\n",
                "                            loc_type='end',\n",
                "                            radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Even though oursim is mostly able to distinguish between 'home', 'library', and 'shopping' at 250m, we are already seeing a concerning 'triangulation' issue in which home, exercise, and library points form the vertices of a triangle cluster that just so happened to randomly cluster unrelated but nearby things together. I think this is partly due to the order in which oursim sees trips, so we should try shuffling trips to see if it changes. Regardless, still slightly worrying. The advantage of DBSCAN is it can identify the dense cores of clusters, which would help to prevent this a little. \n",
                "\n",
                "At 200m, this did not seem to be as much of a problem. ~~Also nice is that oursim is able to cluster the two related trips at a nearby college, which it was unable to do at 150m.~~ (*** Actually, it turns out that the trips to the college were to two separate locations. Foreshadowing some issues we will have with varying density levels...)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Rerunning oursim on shuffled data from user 0 to see if the triangulation still occurs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[3],\n",
                "                            alg='oursim',\n",
                "                            loc_type='end',\n",
                "                            radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ok. So the triangulation did not occur in the same place, but there are definitely weird cluster shapes that basically split up a distinct cluster and include far-away outliers. (Note that the results in the above cell won't appear the same every time since the trips are shuffled randomly.)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "looking at the next user now:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[1],\n",
                "                            alg='DBSCAN',\n",
                "                            loc_type='end',\n",
                "                            radii=[50, 100, 150, 200, 500])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For user1 (who is from the same place as user0), DBSCAN is able to distinguish between the 3 home/library/shopping clusters that were within 2-4 blocks of each other, using a radius of 150m (For the previous user, the max radius to produce distinct clusters was 100m). Again, the worry is that additional data may produce noisy and create 'dendrites' between distinct clusters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[1],\n",
                "                            alg='oursim',\n",
                "                            loc_type='end',\n",
                "                            radii=[100, 150, 200, 250, 300])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here, oursim is able to distinguish the nearby clusters of home, library, and store at a radius of 200m. At 250m, it's still mostly able to distinguish between the 3 clusters, but the shopping clusters at the top right start to get a little weird. At 300m it clumps distinctly unrelated clusters together."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Looking at user2:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[2],\n",
                "                            alg='DBSCAN',\n",
                "                            loc_type='end',\n",
                "                            radii=[50, 100, 150, 200, 500])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This user is a college student, and has work, meal, and home clusters in very close proximity to each other due to density of buildings on college campuses. While DBSCAN is able to distinguish between those at 50m, it is merging clusters at 100m already. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[3],\n",
                "                            alg='oursim',\n",
                "                            loc_type='end',\n",
                "                            radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "With oursim, distinct clusters for school/work/meal/home are found at 100m. By 150m, the clustering is already starting to get wonky (inherent clusters being split into separate clusters with far-away outliers.)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Look at a random user:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[4],\n",
                "                            alg='DBSCAN',\n",
                "                            loc_type='end',\n",
                "                            radii=[50, 100, 150, 200, 500])\n",
                "fig"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[4],\n",
                "                            alg='oursim',\n",
                "                            loc_type='end',\n",
                "                            radii=[50, 100, 150, 200, 500])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### playing with radius selection - start points only"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[0],\n",
                "                            alg='DBSCAN',\n",
                "                            loc_type='start',\n",
                "                            radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "DBSCAN identified distinct home/library/shopping departure clusters at 100m but started merging clusters at 150m."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[0],\n",
                "                            alg='oursim',\n",
                "                            loc_type='start',\n",
                "                            radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Oursim clusters are decently distinct at 200-250m. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[1],\n",
                "                            alg='DBSCAN',\n",
                "                            loc_type='start',\n",
                "                            radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[1],\n",
                "                            alg='oursim',\n",
                "                            loc_type='start',\n",
                "                            radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[3],\n",
                "                            alg='DBSCAN',\n",
                "                            loc_type='start',\n",
                "                            radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "DBSCAN has created a big fat cluster for school/meal/home already at 100m. Not looking great."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = mapping.plot_clusters(expanded_trip_df_map[3],\n",
                "                            alg='oursim',\n",
                "                            loc_type='start',\n",
                "                            radii=[100, 150, 200, 250])\n",
                "fig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "oursim found distinct school/meal/home clusters at 100m. It starts blurring by 150m and some distinct clusters are fully merged by 200m."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Verdict: \n",
                "- oursim produces clusters which have a constrained maximum diameter. if we use it, we should decrease the radius to 100-200m, perhaps 300m if we want to use the technique of getting large clusters and then separating further via SVM or other methods. One major issue is the problem of varying densities and varying scales. For instance, people who frequently visit college campuses may do different things in adjacent buildings. I imagine this problem will also surface when comparing people who live in the suburbs/exurbs vs people living in city downtowns (for example, in the suburb someone may drive out to go to a big grocery store, whereas in the city they may just walk around the corner to a produce store, which may be located right next to a laundromat, the library, the park, etc.)\n",
                "- however, it also sometimes splits the density core of real-world cluster into multiple artificial clusters. DBSCAN doesn't have this issue as much because it finds these density cores. The main issue with DBSCAN is the dendrites. If we use sub-clustering techniques like SVM, we should use DBSCAN as the base clusterer rather than oursim so that the density cores will be intact. \n",
                "\n",
                "TODO: graph the cluster count/request pct/homogeneity/etc as radius grows, then see if there is a region where cluster count/etc stabilizes, and use that to aid radius selection. Also, I would like to test out OPTICS, which is supposed to be slightly better at handling clusters of varying densities. "
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "39792147defedce75a7e3a68ae8b893956023a509c7f6b059d8d59165c20ef2c"
        },
        "kernelspec": {
            "display_name": "Python 3.7.12",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
