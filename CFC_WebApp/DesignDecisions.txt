Documentation of some design decisions around the use of MongoDB
- For the profile and emailUUID databases, do we store the email address in
  _id, or do we use the autogenerated objectID?
  Pros of using _id:
    - can use save (not true, update supports upsert by default)
    - can really ensure only one entry per user (can use update w/upsert
      intelligently to ensure this)
  Cons of using _id:
    - what if we need to have multiple entries per user (maybe for different studies or something)? Multiple is always more flexible than single...
    - can use the ObjectId to get the real create_ts since it is created when
      the entry is created and then never changed. The value that we then
      update can be an update_ts.

  Rescinded Decision: Use the the email address as the _id. If we want to support multiple
    studies, we can have a study list in the profile - in fact, we could start that
    right now. But the user is going to be the same, and we don't want to run
    the profile detection scripts multiple times. Note also that the _id is
    email address, not user, and the user -> email address mapping is not 1:1.

  Updated decision: Use the autogenerated ObjectId as the _id. Much more
    flexible, update with upsert support everything we want anyway. In particular,
    we don't need to look up the _id field because it supports both a query
    field and a new object, and the updated object will use the existing _id
    field if it exists.
    "To replace the entire content of a document except for the _id field, pass
        an entirely new document as the second argument to update()"
--------------------------------------------------------------------------------------
Convention for keys for JSON objects stored in MongoDB: underscores separating words, i.e.
  'user_email', not 'userEmail' or 'user-email'
--------------------------------------------------------------------------------------
Validate entries before they are used, or remove the study in the background or both?
OPEN!

We used to have this check here, but removed it because it would make it harder
to test.  We could get around the testing issue by having a test time, but it
seems easier to just remove the study (in the background) once it is complete,
thus removing that data leak as well.
--------------------------------------------------------------------------------------
How do we support a different kinds of confirmation for individual client plugins?

The carshare project wants us to only ask users to confirm trips that are below
a 90% threshold after the first couple of weeks. We could build this into the
main codebase, but it seems interesting to see if we can build this in
completely in client specific as a thought experiment, and as a way to add more
flexibility to the backend.

This works fine for user specific queries - we can set the auto_classify.prob
in the ML pipeline, and query for it while returning values for a user.

The problem occurs while trying to perform aggregate queries. If we are
iterating over individual sections instead of running a query, we can still
find the user and return the confirmed_mode or the auto_confirmed mode,
depending on the user. But when the mode selection is part of the query, that
doesn't quite work because we will have users from all studies mixed in.

So what we really need is a query that goes like this:
{'confirmed_mode': mode} OR ('confirmed_mode': ''} AND {'study1field': mode} OR {'study2field': mode}...

This means that we need to get a list of fields that each study or client uses
to store its own confirmed trips. There are two ways to do this:
- Dynamically iterate over the client modules using something like:
http://stackoverflow.com/questions/1707709/list-all-the-modules-that-are-part-of-a-python-package
- Create a static query list that needs to be updated for new clients

The tradeoff is between maintainablity and performance. For now, we are going
to go with the second option.  In the future, we should consider having the
static list periodically generated from the modules by an external script, in
order to resolve the tradeoff

--------------------------------------------------------------------------
How do we run client specific background tasks?

There are two options here:
- Client specific: Keep track of a list of clients that require background
  processing, and for each of those, call the client specific runBackgroundTasks method.
  That method is responsible for determining the list of affected users and updating them.

- User specific: Iterate over all users and call the corresponding client
  specific runBackgroundTasks method, if the user has an associated client.

The tradeoff here is between maintainability and performance. If there is a
significant subset of users for whom we don't need to run a background task,
then a client specific view might be more performant. But it requires clients
that do need background tasks to add themselves to a separate list, and is a
different mechanism than the one that we use for the filtering of the trips to
confirm, for example.

Since we currently anticipate using this for all clients, we will go with the
user centered approach.
--------------------------------------------------------------------------
How do we process changes to the user choice?
- Embed JWT into returned HTTP document and reuse it to record switch and to
  reload with POST
    - JWT expires in 1 hour
    - in android, app memory is not reclaimed unless app or activity are
      closed. If Home screen is pressed, app stays in memory without
      suspending, no new call happens, and JWT is not refreshed. So if user
      tries to switch result screen much later, call might fail on server side
      due to failed JWT token
      can't call fresh auth code since current iOS app is not written using cordova.

Embed both result screens + use special HTTP GET method to switch
