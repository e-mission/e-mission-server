{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.storage.timeseries.aggregate_timeseries as estag\n",
    "import emission.storage.timeseries.timequery as estt\n",
    "import arrow\n",
    "import emission.core.get_database as edb\n",
    "from emission.core.wrapper.user import User\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agts = estag.AggregateTimeSeries()\n",
    "sep_dec_tq_data_ts = estt.TimeQuery(\"data.ts\", arrow.get('2018-03-28', 'YYYY-MM-DD').timestamp, arrow.get('2018-06-06', 'YYYY-MM-DD').timestamp)\n",
    "client_nav_events_df = agts.get_data_df(\"stats/client_nav_event\", time_query=sep_dec_tq_data_ts)\n",
    "client_nav_events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_diary_events = client_nav_events_df[client_nav_events_df.name == \"checked_diary\"]\n",
    "print(str(len(checked_diary_events)) + \" total events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information = []\n",
    "emotion = []\n",
    "control = []\n",
    "information_uuids = set()\n",
    "emotion_uuids = set()\n",
    "control_uuids = set()\n",
    "no_clients = set()\n",
    "for i in range(len(checked_diary_events)):\n",
    "    uuid = checked_diary_events[i]['user_id']\n",
    "    try:\n",
    "        client = edb.get_profile_db().find_one({\"user_id\": uuid})['client']\n",
    "        if client == 'urap-2017-information':\n",
    "            information.append(checked_diary_events[i])\n",
    "            information_uuids.add(uuid)\n",
    "        elif client == 'urap-2017-emotion':\n",
    "            emotion.append(checked_diary_events[i])\n",
    "            emotion_uuids.add(uuid)\n",
    "        elif client == 'urap-2017-control':\n",
    "            control.append(checked_diary_events[i])\n",
    "            control_uuids.add(uuid)\n",
    "    except:\n",
    "        no_clients.add(str(uuid))\n",
    "for elem in no_clients:\n",
    "    print(elem + \" doesn't have a client for some reason\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_num_users = len(emotion_uuids)\n",
    "information_num_users = len(information_uuids)\n",
    "control_num_users = len(control_uuids)\n",
    "emotion_total_diary_checks = len(emotion)\n",
    "information_total_diary_checks = len(information)\n",
    "control_total_diary_checks = len(control)\n",
    "print(emotion_num_users, information_num_users, control_num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ('Emotion', 'Information', 'Control')\n",
    "y_pos = range(len(objects))\n",
    "performance = [emotion_total_diary_checks, information_total_diary_checks, control_total_diary_checks]\n",
    "\n",
    "# Total number of diary checks per group\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Diary Checks Per Group')\n",
    "plt.title('Number of Diary Checks')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average diary checks per person\n",
    "performance = [emotion_total_diary_checks/emotion_num_users, information_total_diary_checks/information_num_users, control_total_diary_checks/control_num_users]\n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Average Diary Checks')\n",
    "plt.title('Average Diary Checks Per Person')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Permutation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = edb.get_uuid_db().find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "from datetime import timedelta, date, tzinfo, datetime\n",
    "import numpy as np\n",
    "\n",
    "# Create a dataframe with columns user_id, number of diary checks, week number, and group.\n",
    "df = pd.DataFrame()\n",
    "information_count = 0\n",
    "emotion_count = 0\n",
    "control_count = 0\n",
    "for i in range(len(users)):\n",
    "    user_id = users[i]\n",
    "    start = arrow.get('2018-03-28', 'YYYY-MM-DD')\n",
    "    end = arrow.get('2018-06-06', 'YYYY-MM-DD')\n",
    "    vals = []\n",
    "    week_val = -1\n",
    "    for week in arrow.Arrow.range('week', start, end):\n",
    "        ts = esta.TimeSeries.get_time_series(user_id)\n",
    "        begin_ts = week.timestamp\n",
    "        end_ts = (week + timedelta(weeks=1)).timestamp\n",
    "        last_period_tq = estt.TimeQuery(\"data.start_ts\", begin_ts, end_ts)\n",
    "        cs_df = ts.get_data_df(\"analysis/inferred_section\", time_query=last_period_tq)\n",
    "        total = 0\n",
    "        if cs_df.shape[0] <= 0:\n",
    "            continue\n",
    "        try:\n",
    "            for event in checked_diary_events:\n",
    "                if event['user_id'] == user_id:\n",
    "                    if event['ts'] > begin_ts and event['ts'] <= end_ts:\n",
    "                        total += 1\n",
    "        except:\n",
    "            continue\n",
    "        vals.append(total)\n",
    "    #Always use lists only where the number of datapoints is greater than 2 otherwise we get a perfect correlation\n",
    "    weeks = np.arange(len(vals))\n",
    "    if len(weeks) > 1:\n",
    "        group = \"none\"\n",
    "        try:\n",
    "            client = edb.get_profile_db().find_one({\"user_id\": user_id})['client']\n",
    "            if client == 'urap-2017-information':\n",
    "                group = \"information\"\n",
    "                information_count += 1\n",
    "            elif client == 'urap-2017-emotion':\n",
    "                group = \"emotion\"\n",
    "                emotion_count += 1\n",
    "            elif client == 'urap-2017-control':\n",
    "                group = \"control\"\n",
    "                control_count += 1\n",
    "        except:\n",
    "            continue\n",
    "        df = df.append({'uuid': user_id, 'group': group, 'total': sum(vals)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('group').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_diff(vals_0, vals_1):\n",
    "    return np.mean(vals_0) - np.mean(vals_1)\n",
    "\n",
    "def perm_test(labels, response_vars, stat_func, n):\n",
    "    '''Labels: Series with two labels, Response_vars series in same order as labels\n",
    "    stat_func is a function that takes in two series and returns a statistic, n is permutation numnber'''\n",
    "    unique_label_counts = labels.value_counts()\n",
    "    label_0 = unique_label_counts.index[0]\n",
    "    label_1 = unique_label_counts.index[1]\n",
    "    label_0_count = unique_label_counts[0]\n",
    "    label_1_count = unique_label_counts[1]\n",
    "    vals_0 = response_vars[labels == label_0]\n",
    "    vals_1 = response_vars[labels == label_1]\n",
    "    observed_stat = stat_func(vals_0, vals_1)\n",
    "    sample_stats = np.array([])\n",
    "    ind = labels\n",
    "    for i in range(n):\n",
    "        sampler = np.random.permutation(label_0_count + label_1_count)\n",
    "        new_vals = response_vars.take(sampler).values\n",
    "        df = pd.DataFrame({'vals': new_vals}, index=ind)\n",
    "        vals_0 = df[df.index == label_0]['vals']\n",
    "        vals_1 = df[df.index == label_1]['vals']\n",
    "        stat = stat_func(vals_0, vals_1)\n",
    "        sample_stats = np.append(sample_stats, stat)\n",
    "    perm_mean = np.mean(sample_stats)\n",
    "    plt.hist(sample_stats)\n",
    "    plt.show()\n",
    "    if observed_stat > perm_mean:\n",
    "        p = np.sum(sample_stats > observed_stat) / len(sample_stats)\n",
    "    else:\n",
    "        p = np.sum(sample_stats < observed_stat) / len(sample_stats)\n",
    "    error = np.sqrt(p*(1-p)/n) * 2 * 100\n",
    "    print(\"p val: \" + str(p), \"error percent = \" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_c = df[df['group'] != 'information']\n",
    "perm_test(e_c['group'], e_c['total'], mean_diff, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_c = df[df['group'] != 'emotion']\n",
    "perm_test(i_c['group'], i_c['total'], mean_diff, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i_e = df[df['group'] != 'control']\n",
    "perm_test(i_e['group'], i_e['total'], mean_diff, 100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
