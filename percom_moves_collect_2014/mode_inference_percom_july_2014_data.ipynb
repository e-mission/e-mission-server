{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data caveats\n",
    "\n",
    "1. This is based on data collected on the UC Berkeley campus in Spring 2014. Unfortunately, due to the sensitive nature of the data collected (location data), the dataset cannot be shared, but the corresponding author can run queries against it and return the aggregate results upon request.\n",
    "2. Since the initial results were not run with a fixed random seed, the results in this notebook differ slightly from the published results, but they are generally consistent. And any subsequent results should be identical since this notebook contains a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collected some more training data after this, but it was not included in these results.\n",
    "So let us read the data from the backup database to ensure consistency with the published results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sections = pymongo.MongoClient('localhost').Backup_database.Stage_Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sections.find({'type': 'move'}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "np.random.seed(61297777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmedSections = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walkSections = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': 1}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeList = json.load(open(\"modes.json\"))\n",
    "print(modeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}]}).count())\n",
    "modeNameList = []\n",
    "modeCountList = []\n",
    "for mode in modeList:\n",
    "    modeCount = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': mode['mode_id']}]}).count()\n",
    "    print(\"%s, %s\" % (mode['mode_name'], modeCount))\n",
    "    if modeCount > 0:\n",
    "        modeNameList.append(mode['mode_name'])\n",
    "        modeCountList.append(modeCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import displayHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanModeNames = {\"walking\":\"walk\", \"running\":\"run\", \"cycling\":\"cycle\"}\n",
    "(fig, ax) = displayHelpers.showCategoryChart(modeNameList, [modeCountList], ['Confirmed'], ['r'],\n",
    "                                             \"Number of trip sections\", \"Trip sections by mode\", \n",
    "                                             cleanNameDict = cleanModeNames, figsize=(12,5))\n",
    "ax.set_ylim(top=4000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTimes = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}]}, {'section_start_datetime': 1, '_id': 0}).sort('section_start_datetime', pymongo.ASCENDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSections = startTimes.count()\n",
    "print(\"Starting from %s\" % startTimes[0])\n",
    "print(\"Ending at %s\" % startTimes[nSections-1])\n",
    "startTime = startTimes[0]['section_start_datetime']\n",
    "endTime = startTimes[nSections-1]['section_start_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeNameList = []\n",
    "timeCountList = []\n",
    "timeTotalList = []\n",
    "currTime = startTime\n",
    "while currTime < endTime:\n",
    "    currEndTime = currTime + timedelta(days=30)\n",
    "    if currEndTime > endTime:\n",
    "        currEndTime = endTime\n",
    "    currTimeSearch = {'section_start_datetime': {\"$gte\": currTime, \"$lte\": currEndTime}}\n",
    "    nTrips = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}, currTimeSearch]}, {'section_start_datetime': 1, '_id': 0}).count()\n",
    "    nTotalTrips = Sections.find({\"$and\": [{'type': 'move'}, currTimeSearch]}, {'section_start_datetime': 1, '_id': 0}).count()\n",
    "    print(\"%s - %s = %s, %s\" % (currTime.strftime(\"%m-%d\"), currEndTime, nTrips, nTotalTrips))\n",
    "    timeNameList.append(\"%s to %s\" % (currTime.strftime(\"%b-%d\"), currEndTime.strftime(\"%b-%d\")))\n",
    "    timeCountList.append(nTrips)\n",
    "    timeTotalList.append(nTotalTrips)\n",
    "    currTime = currEndTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig, ax) = displayHelpers.showCategoryChart(timeNameList[:-1], [timeCountList[:-1], timeTotalList[:-1]],\n",
    "                                             [\"Confirmed\", \"Total\"], ['r', 'b'], \n",
    "                                             \"Number of trip sections\", \"Trip sections by start time\", figsize=(12,5))\n",
    "# ax.set_ylim(top=5500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeNameList = []\n",
    "timeCountList = []\n",
    "timeTotalList = []\n",
    "currTime = datetime(year=2014,month=5,day=6)\n",
    "while currTime < endTime:\n",
    "    currTimeSearch = {'section_start_datetime': {\"$lte\": currTime}}\n",
    "    nTrips = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}, currTimeSearch]}, {'section_start_datetime': 1, '_id': 0}).count()\n",
    "    nTotalTrips = Sections.find({\"$and\": [currTimeSearch]}, {'section_start_datetime': 1, '_id': 0}).count()\n",
    "    print(\"%s = %s, %s\" % (currTime.strftime(\"%m-%d\"), nTrips, nTotalTrips))\n",
    "    timeNameList.append(\"%s\" % (currTime.strftime(\"%b-%d\")))\n",
    "    timeCountList.append(nTrips)\n",
    "    timeTotalList.append(nTotalTrips)\n",
    "    currTime = currTime + timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idList = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}]}).distinct('user_id')\n",
    "idNameList = []\n",
    "idCountList = []\n",
    "confirmedCountList = []\n",
    "for i, id in enumerate(idList):\n",
    "    count = Sections.find({\"$and\": [{'type': 'move'}, {'user_id': id}]}).count()\n",
    "    confirmedCount = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}, {'user_id': id}]}).count()\n",
    "    print(id, count, confirmedCount)\n",
    "    idNameList.append(\"%s\" % i)\n",
    "    idCountList.append(count)\n",
    "    confirmedCountList.append(confirmedCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = displayHelpers.showCategoryChart(idNameList, [confirmedCountList, idCountList],\n",
    "                                             [\"Confirmed Sections\", \"Total Sections\"],\n",
    "                                             ['r', 'b'], \"Number of trip sections\", \"Trip sections by user\", figsize=(12,5))\n",
    "oldSize = mpl.rcParams['font.size']\n",
    "mpl.rcParams['font.size'] = 16\n",
    "labels = range(0, len(idNameList), 5)\n",
    "axes.set_xticks(labels)\n",
    "axes.set_xticklabels(np.array(idNameList)[labels])\n",
    "fig.show()\n",
    "mpl.rcParams['font.size'] = oldSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurecalc import calDistance, calSpeed, calHeading, calAvgSpeed, calSpeeds, calAccels, getIthMaxSpeed, getIthMaxAccel, calHCR,\\\n",
    "calSR, calVCR, mode_cluster, mode_start_end_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeedsForMode(modeId):\n",
    "    modeSectionCursor = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': modeId}]})\n",
    "    speedList = []\n",
    "    for section in modeSectionCursor:\n",
    "        speeds = calSpeeds(section)\n",
    "        if speeds != None:\n",
    "            # currHistogram = sp.histogram(speeds)\n",
    "            speedList.append(speeds)\n",
    "    return speedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matrix construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features are:\n",
    "# 0. distance\n",
    "# 1. duration\n",
    "# 2. first filter mode\n",
    "# 3. sectionId\n",
    "# 4. avg speed\n",
    "# 5. speed EV\n",
    "# 6. speed variance\n",
    "# 7. max speed\n",
    "# 8. max accel\n",
    "# 9. isCommute\n",
    "# 10. heading change rate (currently unfilled)\n",
    "# 11. stop rate (currently unfilled)\n",
    "# 12. velocity change rate (currently unfilled)\n",
    "# 13. start lat\n",
    "# 14. start lng\n",
    "# 15. stop lat\n",
    "# 16. stop lng\n",
    "# 17. start hour\n",
    "# 18. end hour\n",
    "# 19. both start and end close to bus stop\n",
    "# 20. both start and end close to train station\n",
    "# 21. both start and end close to airport\n",
    "featureLabels = [\"distance\", \"duration\", \"first filter mode\", \"sectionId\", \"avg speed\",\n",
    "                 \"speed EV\", \"speed variance\", \"max speed\", \"max accel\", \"isCommute\",\n",
    "                 \"heading change rate\", \"stop rate\", \"velocity change rate\", \"start lat\", \"start lng\",\n",
    "                 \"stop lat\", \"stop lng\", \"start hour\", \"end hour\", \"close to bus stop\", \"close to train stop\",\n",
    "                 \"close to airport\"]\n",
    "bus_cluster=mode_cluster(5,105,1)\n",
    "train_cluster=mode_cluster(6,600,1)\n",
    "air_cluster=mode_cluster(9,600,1)\n",
    "def generateFeatureMatrixAndResultVector(sectionQuery):\n",
    "    confirmedSections = Sections.find(sectionQuery)\n",
    "    featureMatrix = np.zeros([confirmedSections.count(), len(featureLabels)])\n",
    "    resultVector = np.zeros(confirmedSections.count())\n",
    "    for (i, section) in enumerate(confirmedSections):\n",
    "        featureMatrix[i, 0] = section['distance']\n",
    "        featureMatrix[i, 1] = (section['section_end_datetime'] - section['section_start_datetime']).total_seconds()\n",
    "        \n",
    "        # Deal with unknown modes like \"airplane\"\n",
    "        try:\n",
    "            featureMatrix[i, 2] = section['mode']\n",
    "        except ValueError:\n",
    "            featureMatrix[i, 2] = 0\n",
    "            \n",
    "        featureMatrix[i, 3] = section['section_id']\n",
    "        featureMatrix[i, 4] = calAvgSpeed(section)\n",
    "        speeds = calSpeeds(section)\n",
    "        if speeds != None:\n",
    "            featureMatrix[i, 5] = np.mean(speeds)\n",
    "            featureMatrix[i, 6] = np.std(speeds)\n",
    "            featureMatrix[i, 7] = np.max(speeds)\n",
    "        else:\n",
    "            # They will remain zero\n",
    "            pass\n",
    "        accels = calAccels(section)\n",
    "        if accels != None and len(accels) > 0:\n",
    "            featureMatrix[i, 8] = np.max(accels)\n",
    "        else:\n",
    "            # They will remain zero\n",
    "            pass\n",
    "        featureMatrix[i, 9] = ('commute' in section) and (section['commute'] == 'to' or section['commute'] == 'from')\n",
    "        featureMatrix[i, 10] = calHCR(section)\n",
    "        featureMatrix[i, 11] = calSR(section)\n",
    "        featureMatrix[i, 12] = calVCR(section)\n",
    "        if section['section_start_point'] != None:\n",
    "            startCoords = section['section_start_point']['coordinates']\n",
    "            featureMatrix[i, 13] = startCoords[0]\n",
    "            featureMatrix[i, 14] = startCoords[1]\n",
    "        \n",
    "        if section['section_end_point'] != None:\n",
    "            endCoords = section['section_end_point']['coordinates']\n",
    "            featureMatrix[i, 15] = endCoords[0]\n",
    "            featureMatrix[i, 16] = endCoords[1]\n",
    "        \n",
    "        featureMatrix[i, 17] = section['section_start_datetime'].time().hour\n",
    "        featureMatrix[i, 18] = section['section_end_datetime'].time().hour\n",
    "        \n",
    "        featureMatrix[i, 19] = mode_start_end_coverage(section,bus_cluster,105)\n",
    "        featureMatrix[i, 20] = mode_start_end_coverage(section,train_cluster,600)\n",
    "        featureMatrix[i, 21] = mode_start_end_coverage(section,air_cluster,600)\n",
    "        resultVector[i] = section['confirmed_mode']\n",
    "    return (featureMatrix, resultVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(featureMatrix, resultVector) = generateFeatureMatrixAndResultVector({\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(featureMatrix[:,10]))\n",
    "print(np.max(featureMatrix[:,20]))\n",
    "print(np.max(featureMatrix[:,12]))\n",
    "print(featureMatrix.shape, resultVector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runIndices = resultVector == 2\n",
    "transportIndices = resultVector == 4\n",
    "mixedIndices = resultVector == 8\n",
    "airIndices = resultVector == 9\n",
    "unknownIndices = resultVector == 0\n",
    "strippedIndices = np.logical_not(runIndices | transportIndices | mixedIndices)\n",
    "print(\"runIndices = %s\" % (np.nonzero(runIndices)))\n",
    "print(\"transportIndices = %s\" % (np.nonzero(transportIndices)))\n",
    "print(\"mixedIndices = %s\" % (np.nonzero(mixedIndices)))\n",
    "print(\"airIndices = %s\" % (np.nonzero(airIndices)))\n",
    "print(\"unknownIndices = %s\" % (np.nonzero(unknownIndices)))\n",
    "print(\"strippedIndices count = %s\" % (np.count_nonzero(strippedIndices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we filter out \"mixed\" and \"running\", since there are few instances of them and we don't intend to predict them initially. We also filter out any \"transport\" since it should never be in the confirmed set, and we don't want to deal with it if it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strippedFeatureMatrix = featureMatrix[strippedIndices]\n",
    "strippedResultVector = resultVector[strippedIndices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we visualize the distribution of some of the features. This is so that we can compare our dataset to Zheng et al 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFeatureVector(featureMatrix, resultVector, featureIndex, modeList):\n",
    "    avgSpeedFig, avgSpeedAxes = plt.subplots(1,1)\n",
    "    currModeSpeedsList = []\n",
    "    currModeNamesList = []\n",
    "    for mode in modeList:\n",
    "        currModeMask = resultVector == mode['mode_id']\n",
    "        currModeSpeeds = featureMatrix[currModeMask, featureIndex]\n",
    "        # print \"For mode %s, shape is %s\" % (mode['mode_id'], str(currModeSpeeds.shape))\n",
    "        if np.count_nonzero(currModeMask) != 0:\n",
    "            currModeNamesList.append(mode['mode_name'])\n",
    "            currModeSpeedsList.append(currModeSpeeds)\n",
    "    avgSpeedAxes.hist(currModeSpeedsList, normed=True, histtype=\"bar\", label=currModeNamesList)\n",
    "    avgSpeedAxes.set_ylabel(\"number of segments\")\n",
    "    avgSpeedAxes.set_xlabel(featureLabels[featureIndex])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(0, len(featureLabels)):\n",
    "    plotFeatureVector(strippedFeatureMatrix, strippedResultVector, col, modeList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The air modes are such outliers that we are unable to see the variation in the other modes. Let's strip out the outliers and focus on lower speed trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedNormalEntries = strippedFeatureMatrix[:,4] < 50\n",
    "plotFeatureVector(strippedFeatureMatrix[speedNormalEntries], strippedResultVector[speedNormalEntries], 4, modeList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graphs above, we can estimate the separability of our input. Clearly, there is some separability - the car and train trips that are at 20-30+ are clearly separable from the walk/bike trips that are at lower speeds. But are they separable from each other? And at least eyeballing the data, it looks like at least 75% of car trips are actually not that fast - the mean EV is < 10mph. Even with max speed, at least 25% of car trips appear to have a max speed ~ 10 mph. Max accel doesn't seem to have as much predictive power as one might hope - most max accel clusters at less than 5. It would be nice to visualize the clusters in this data, but I'm just going to start trying decision trees and SVMs on this data now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used to strip out outliers here, but the outliers actually correspond to plane trips, so we want to retain them. The rest of the code assumes that we stripped outliers to get \"cleaned\" trips, so we just reassign the values here instead of changing all the code. We can restore outlier detection at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedFeatureMatrix = strippedFeatureMatrix\n",
    "cleanedResultVector = strippedResultVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genericFeatureIndices = list(range(0,10))\n",
    "AdvancedFeatureIndices = list(range(10,13))\n",
    "LocationFeatureIndices = list(range(13,17))\n",
    "TimeFeatureIndices = list(range(17,19))\n",
    "BusTrainFeatureIndices = list(range(19,22))\n",
    "print(genericFeatureIndices)\n",
    "print(AdvancedFeatureIndices)\n",
    "print(LocationFeatureIndices)\n",
    "print(TimeFeatureIndices)\n",
    "print(BusTrainFeatureIndices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic model, generic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genericCleanedFM = cleanedFeatureMatrix[:,genericFeatureIndices]\n",
    "print(genericCleanedFM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmClf = svm.LinearSVC()\n",
    "svmScores = cross_validation.cross_val_score(svmClf, genericCleanedFM, cleanedResultVector, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svmScores)\n",
    "print(svmScores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using svm.SVC() takes significantly longer (hours instead of seconds) but generates higher accuracy. The accuracy is still lower than the random forest, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "forestScores = cross_validation.cross_val_score(forestClf, genericCleanedFM, cleanedResultVector, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forestScores)\n",
    "print(forestScores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results look pretty good, and pretty much parallel what the Zheng paper got, even with just the basic features. We get 82% average accuracy for a linear SVM and 86% average accuracy for a random forest. But the 82% and 86% values are for cross validation, where we have a known value that we can validate against.\n",
    "\n",
    "But what we really want to do is to decide, while looking at a section that we have no ground truth on, whether we want the user to classify it or not. And then we want to see, for the high confidence predictions that we will not prompt the user for, how accurate our classification really is.\n",
    "\n",
    "In order to do this, we get the probabilities for each prediction in addition to the prediction itself. We can then test the accuracy of the high confidence predictions and compare it to the accuracy of all predictions.\n",
    "\n",
    "To recap, we now return three metrics:\n",
    "\n",
    "- The number of entries that would be autoclassified given a particular target confidence interval\n",
    "- The accuracy of the entries that would be autoclassified\n",
    "- The accuracy of all entries, including ones that had low confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate folds of indices\n",
    "def generateFoldArrays(nIndices, nFolds):\n",
    "    currPermutation = np.random.permutation(nIndices)\n",
    "    currPermutationParts = np.array_split(currPermutation, nFolds)\n",
    "    \n",
    "    foldArrays = []\n",
    "    for i in range(0, nFolds):\n",
    "        testIndices = currPermutationParts[i]\n",
    "        trainIndicesParts = [currPermutationPart for (j, currPermutationPart) in enumerate(currPermutationParts) if j != i]\n",
    "        trainIndices = np.concatenate(trainIndicesParts)\n",
    "        foldArrays.append((trainIndices, testIndices))\n",
    "    return foldArrays\n",
    "\n",
    "def kFoldValidationWithProb(algo, X, y, nFolds, prob_threshold):\n",
    "    foldArrays = generateFoldArrays(len(y), nFolds)\n",
    "    \n",
    "    scores = []\n",
    "    highConfidenceScores = []\n",
    "    percentAutoClassified = []\n",
    "    percentAutoClassifiedByMode = []\n",
    "    for (trainIndices, testIndices) in foldArrays:\n",
    "        # print testIndices[0]\n",
    "        model = algo.fit(X[trainIndices], y[trainIndices])\n",
    "        testX = X[testIndices]\n",
    "        testy = y[testIndices]\n",
    "        \n",
    "        predictedY = model.predict(testX)\n",
    "        if hasattr(algo, \"decision_function\"):\n",
    "            predictedYProb = algo.decision_function(testX)\n",
    "        else:\n",
    "            predictedYProb = algo.predict_proba(testX)\n",
    "        \n",
    "        # print (\"predictedY.shape = %s, predictedYProb.shape = %s\" %\n",
    "        #        (str(predictedY.shape), str(predictedYProb.shape)))\n",
    "        \n",
    "        # As we can see below, we take the max confidence along the first axis\n",
    "        highConfidencePredictions = np.max(predictedYProb, 1) > prob_threshold\n",
    "        print(\"Found %s high confidence predictions out of %s\" % (np.count_nonzero(highConfidencePredictions),\n",
    "                                                                  len(testIndices)))\n",
    "        \n",
    "        cmc = lambda m:np.count_nonzero(testy[highConfidencePredictions] == m)\n",
    "        \n",
    "        # Let us see how many of each mode were autoclassified\n",
    "        # print(\"Autoclassifications split by confirmed modes: walk: %s, bike: %s, bus: %s, train: %s, car: %s\" %\n",
    "        #       (cmc(1), cmc(3), cmc(5), cmc(6), cmc(7)))\n",
    "        \n",
    "        pcmc = lambda m: float(np.count_nonzero(testy[highConfidencePredictions] == m))/np.count_nonzero(testy == m) if ((np.count_nonzero(testy == m) != 0)) else 0 \n",
    "        # Let us see what percentage of each mode was autoclassified\n",
    "        # print(\"For threshold %s, autoclassifications split by confirmed mode percents: walk: %s, bike: %s, bus: %s, train: %s, car: %s\" %\n",
    "        #        (prob_threshold, pcmc(1), pcmc(3), pcmc(5), pcmc(6), pcmc(7)))\n",
    "        \n",
    "        percentAutoClassified.append(float(np.count_nonzero(highConfidencePredictions))/len(testIndices))\n",
    "        percentAutoClassifiedByMode.append([pcmc(1), pcmc(3), pcmc(5), pcmc(6), pcmc(7), pcmc(9)])\n",
    "        \n",
    "        # so now we are going to generate two scores.\n",
    "        # the first is the score on only the high confidence predictions\n",
    "        highConfidenceScore = model.score(testX[highConfidencePredictions], testy[highConfidencePredictions])\n",
    "        highConfidenceScores.append(highConfidenceScore)\n",
    "        \n",
    "        score = model.score(X[testIndices], y[testIndices])\n",
    "        scores.append(score)\n",
    "    # print scores\n",
    "    \n",
    "    print(\"for prob %s, percentage auto classified %s\" % (prob_threshold, np.array(percentAutoClassified).mean()))\n",
    "    print(\"for prob %s, scoring only on high confidence predictions %s\" % (prob_threshold, np.array(highConfidenceScores).mean()))\n",
    "    print(\"for prob %s, scoring on all predictions %s\" % (prob_threshold, np.array(scores).mean()))\n",
    "\n",
    "    return (np.array(percentAutoClassified), np.array(percentAutoClassifiedByMode), np.array(highConfidenceScores), np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploreKFoldValidationSpace(algo, X, y, nFolds):\n",
    "    (pac0, pacm0, hcs0, s0) = kFoldValidationWithProb(algo, X, y, nFolds, 0.90)    \n",
    "    (pac5, pacm5, hcs5, s5) = kFoldValidationWithProb(algo, X, y, nFolds, 0.95)\n",
    "    (pac9, pacm9, hcs9, s9) = kFoldValidationWithProb(algo, X, y, nFolds, 0.99)\n",
    "    \n",
    "    probs = [0.90, 0.95, 0.99]\n",
    "    pacs = [pac0.mean(), pac5.mean(), pac9.mean()]\n",
    "    hcs = [hcs0.mean(), hcs5.mean(), hcs9.mean()]\n",
    "    ss = [s0.mean(), s5.mean(), s9.mean()]\n",
    "    \n",
    "    pacmWalk = [pacm0[:,0].mean(), pacm5[:,0].mean(), pacm9[:,0].mean()]\n",
    "    pacmBike = [pacm0[:,1].mean(), pacm5[:,1].mean(), pacm9[:,1].mean()]\n",
    "    pacmBus = [pacm0[:,2].mean(), pacm5[:,2].mean(), pacm9[:,2].mean()]\n",
    "    pacmTrain = [pacm0[:,3].mean(), pacm5[:,3].mean(), pacm9[:,3].mean()]\n",
    "    pacmCar = [pacm0[:,4].mean(), pacm5[:,4].mean(), pacm9[:,4].mean()]\n",
    "    pacmAir = [pacm0[:5].mean(), pacm5[:,5].mean(), pacm9[:,4].mean()]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 1, figsize=(15, 10))\n",
    "    print(pacs)\n",
    "    axes.set_yticks(np.arange(0,1,0.1))\n",
    "    axes.plot(probs, pacs, label=\"percentage auto classified\")\n",
    "    \n",
    "    print(pacmWalk)\n",
    "    axes.plot(probs, pacmWalk, linewidth = 5, label=\"percent walk auto classified\")\n",
    "    print(pacmBike)\n",
    "    axes.plot(probs, pacmBike, label=\"percent bike auto classified\")\n",
    "    print(pacmBus)\n",
    "    axes.plot(probs, pacmBus, linewidth=5, label=\"percent bus auto classified\")\n",
    "    print(pacmTrain)\n",
    "    axes.plot(probs, pacmTrain, label=\"percent train auto classified\")\n",
    "    print(pacmCar)\n",
    "    axes.plot(probs, pacmCar, linewidth=5, label=\"percent car auto classified\")\n",
    "    print(pacmAir)\n",
    "    axes.plot(probs, pacmAir, linewidth=5, label = \"percent air auto classified\")\n",
    "    \n",
    "    print(hcs)\n",
    "    axes.plot(probs, hcs, label=\"accuracy of high confidence samples\")\n",
    "    print(ss)\n",
    "    axes.plot(probs, ss, linewidth = 5, label=\"accuracy of all samples\")\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, genericCleanedFM, cleanedResultVector, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of these three metrics for confidence intervals of 90%, 95% and 99% are shown above, and they are all largely similar. The accuracy of the high confidence predictions is, as expected, really high at 97 - 98%. However, we were only able to auto-classify ~ 50% of the sections. Now, let's retry using the linear SVM above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmClf = svm.LinearSVC()\n",
    "exploreKFoldValidationSpace(svmClf, genericCleanedFM, cleanedResultVector, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the SVM is able to classify more trips than the decision tree, but at the cost of unacceptably lower performance on the high confidence predictions. It is hard to understand the results with line plots, let's switch to bar graphs instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploreKFoldValidationSpaceBarGraph(algo, X, y, nFolds):\n",
    "    (pac0, pacm0, hcs0, s0) = kFoldValidationWithProb(algo, X, y, nFolds, 0.90)    \n",
    "    (pac5, pacm5, hcs5, s5) = kFoldValidationWithProb(algo, X, y, nFolds, 0.95)\n",
    "    (pac9, pacm9, hcs9, s9) = kFoldValidationWithProb(algo, X, y, nFolds, 0.99)\n",
    "    \n",
    "    probs = [0.90, 0.95, 0.99]\n",
    "    pacs = [pac0.mean() * 100, pac5.mean() * 100, pac9.mean() * 100]\n",
    "    hcs = [hcs0.mean() * 100, hcs5.mean() * 100, hcs9.mean() * 100]\n",
    "    ss = [s0.mean() * 100, s5.mean() * 100, s9.mean() * 100]\n",
    "    \n",
    "    mpl.rcParams['font.size'] = 16\n",
    "    fig, axes = displayHelpers.showCategoryChart([\"90%\", \"95%\", \"99%\"], [pacs, hcs, ss],\n",
    "                                                       [\"% high confidence\", \"high confidence accuracy\", \"overall accuracy\"],\n",
    "                                                       ['r', 'g', 'b'], \"Percent\", \"High confidence predictions\",\n",
    "                                                       width=0.15, figsize=(6,5))\n",
    "    axes.set_yticks(range(0, 100, 10))\n",
    "    axes.axhline(50, label = \"50%\")\n",
    "    axes.axhline(90, label = \"90%\")\n",
    "    # axes.get_legend().set_bbox_\n",
    "    axes.set_ylim(top=100)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpaceBarGraph(forestClf, cleanedFeatureMatrix, cleanedResultVector, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmClf = svm.LinearSVC()\n",
    "exploreKFoldValidationSpaceBarGraph(svmClf, cleanedFeatureMatrix, cleanedResultVector, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get the most important params for the decision tree so that we can better understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, importance) in enumerate(forestClf.feature_importances_):\n",
    "    print(featureLabels[i], importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the highest importance features are:\n",
    "\n",
    "- first filter mode (moves mode)\n",
    "- speed EV\n",
    "- avg speed\n",
    "- distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try another non-parametric method like nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClf = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploreKFoldValidationSpace(knnClf, cleanedFeatureMatrix, cleanedResultVector, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn does almost the same as decision tree, except that the accuracy of the high confidence predictions is a bit lower.\n",
    "I think that the percentages are around the same as well. Basically, we can classify walk pretty well and the others pretty poorly.\n",
    "So I am not sure what we are adding here over moves :)\n",
    "\n",
    "I'm surprised at the low prediction rate for cycling. Moves seems to get that pretty accurately for me.\n",
    "\n",
    "I'm now going to plot this data and see what it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced features added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Advanced_indices=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "print(Advanced_indices)\n",
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix[:,Advanced_indices], cleanedResultVector, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial knowledge added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spatial_indices=[0,1,2,3,4,5,6,7,8,9,13,14,15,16,17,18,19,20]\n",
    "print(Spatial_indices)\n",
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix[:,Spatial_indices], cleanedResultVector, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location and time features added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix, cleanedResultVector, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClf = neighbors.KNeighborsClassifier()\n",
    "exploreKFoldValidationSpace(knnClf, cleanedFeatureMatrix, cleanedResultVector, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, importance) in enumerate(forestClf.feature_importances_):\n",
    "    print(featureLabels[i], importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more contour plots to help us visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printColorMap(algo, Xall, y):\n",
    "    # we want to split roughly into roughly 10-20 sections\n",
    "    nSplits = 20\n",
    "    \n",
    "    # setup parameters\n",
    "    cmap_light = colors.ListedColormap(['#FAAAAA', '#AFAAAA', '#AAFAAA', '#AAAFAA', '#AAAAFA', '#AAAAAF'])\n",
    "    cmap_bold = colors.ListedColormap(['#F00000', '#0F0000', '#00F000', '#000F00', '#0000F0', '#00000F'])\n",
    "   \n",
    "    # nFeatures = Xall.shape[1]\n",
    "    nFeatures = 10\n",
    "    fig, axes = plt.subplots(20, 5, figsize=(15,50))\n",
    "    plt.tight_layout()\n",
    "    axesArr = axes.flatten()\n",
    "        \n",
    "    i = 0\n",
    "    for selCombo in itertools.product(np.arange(nFeatures), np.arange(nFeatures)):\n",
    "        if selCombo[0] == selCombo[1]:\n",
    "            continue\n",
    "        # print(\"Generating grid for combo %s,%s in slot %s\" % (featureLabels[selCombo[0]], featureLabels[selCombo[1]], i))\n",
    "        \n",
    "        selMask = np.zeros(Xall.shape[1])\n",
    "        # Otherwise, we won't be able to plot it properly below\n",
    "        assert(len(selCombo) == 2)\n",
    "        selMask[selCombo[0]] = 1\n",
    "        selMask[selCombo[1]] = 1\n",
    "    \n",
    "        X = Xall[:,selMask == 1]\n",
    "    \n",
    "        algo.fit(X, y)\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        # we want to split roughly into \n",
    "        h_x = float(x_max - x_min) / nSplits\n",
    "        h_y = float(y_max - y_min) / nSplits\n",
    "        \n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h_x),\n",
    "                             np.arange(y_min, y_max, h_y))\n",
    "        Z = algo.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        axesArr[i].pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "        # Plot also the training points\n",
    "        axesArr[i].scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "        # plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "        axesArr[i].set_xlim(xx.min(), xx.max())\n",
    "        axesArr[i].set_ylim(yy.min(), yy.max())\n",
    "        axesArr[i].set_title(\"%s v/s %s\" % (featureLabels[selCombo[0]], featureLabels[selCombo[1]]))\n",
    "        # axesArr[i].legend(loc='best')\n",
    "        i = i+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printColorMap(forestClf, cleanedFeatureMatrix, cleanedResultVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also quickly take a look at the confusion matrix for the overall model. Because maybe we should not care about the confidence of the predictions, and just weight them lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printConfusionMatrix(algo, X, y, title):\n",
    "    skf = cross_validation.StratifiedKFold(y, 5)\n",
    "    nClasses = np.count_nonzero(np.unique(y))\n",
    "    print(\"nClasses = %s\" % nClasses)\n",
    "    sumPCM = np.zeros([nClasses, nClasses])\n",
    "    for train, test in skf:\n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "        print(\"Number of distinct classes in training set = %s, test set = %s\" % (np.unique(y[train]), np.unique(y[test])))\n",
    "        y_pred = algo.fit(X_train, y_train).predict(X_test)\n",
    "        # This has the raw number of entries (e.g. [610  12   1   0  32   1])\n",
    "        # Since the total number of entries for each mode is different, we want to convert this to a percentage\n",
    "        cmraw = metrics.confusion_matrix(y_test, y_pred)\n",
    "        # We do that by summing up the entries for each mode (e.g. 656)\n",
    "        sumArr = np.sum(cmraw, axis=1)\n",
    "        # and repeating it across the row (e.g. [656 656 656 656 656 656])\n",
    "        repeatedSumArr = np.repeat(sumArr, cmraw.shape[1]).reshape(cmraw.shape)\n",
    "        # And dividing the raw numbers by the sums to get percentages (e.g [92.98 1.82 0 4.87 0.15])\n",
    "        sumPCM = np.add(sumPCM, np.divide(cmraw.astype(float), repeatedSumArr))\n",
    "    \n",
    "    finalPCM = sumPCM / 5\n",
    "    logFinalPCM = np.log(finalPCM + 1)\n",
    "    np.set_printoptions(precision=0, suppress=True)\n",
    "    # np.set_printoptions(precision=4, suppress=False)\n",
    "    print(finalPCM * 100)\n",
    "\n",
    "    oldSize = mpl.rcParams['font.size']\n",
    "    mpl.rcParams['font.size'] = 16\n",
    "    (fig, ax) = plt.subplots()\n",
    "    # First element is \"\" because of http://stackoverflow.com/questions/3529666/matplotlib-matshow-labels\n",
    "    ax.set_xticklabels([\"\",\"walk\", \"\", \"bus\", \"\", \"car\", \"\"])\n",
    "    ax.set_yticklabels([\"\",\"walk\", \"cycle\", \"bus\", \"train\", \"car\", \"air\"])\n",
    "    cax = ax.matshow(logFinalPCM, cmap=cm.gray)\n",
    "    ax.set_title(title, color='green', weight='bold', size=16, y=1.1)\n",
    "    \n",
    "    fig.colorbar(cax)\n",
    "    ax.set_ylabel('True label', size=\"large\")\n",
    "    ax.set_xlabel('Predicted label', size=\"large\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return (finalPCM, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCMList = []\n",
    "saveDir = \"/tmp/ml_results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(saveDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "printConfusionMatrix(forestClf, genericCleanedFM, cleanedResultVector, \"Generic features, random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "printConfusionMatrix(forestClf, cleanedFeatureMatrix[:,Spatial_indices], cleanedResultVector, \"Spatial Features, random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "currCM, fig = printConfusionMatrix(forestClf, cleanedFeatureMatrix, cleanedResultVector, \"All features, random forest\")\n",
    "fig.savefig(saveDir+\"cm_all_random_forest.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding start and end points does improve the accuracy of the bus and train. Train trips in particular, are significantly improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClf = neighbors.KNeighborsClassifier()\n",
    "printConfusionMatrix(knnClf, genericCleanedFM, cleanedResultVector, \"Generic features, k-nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClf = neighbors.KNeighborsClassifier()\n",
    "currCM, fig = printConfusionMatrix(knnClf, cleanedFeatureMatrix, cleanedResultVector, \"All features, k-nn\")\n",
    "fig.savefig(saveDir+\"cm_all_k_nn.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn does significantly worse, primarily because of bus trips. I suspect this is because different people make the same trip using different modes. Time for per-user trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmClf = svm.LinearSVC()\n",
    "currCM, fig = printConfusionMatrix(svmClf, cleanedFeatureMatrix, cleanedResultVector, \"All features, Linear SVM\")\n",
    "fig.savefig(saveDir+\"cm_all_linear_svm.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For parametric models, it is particularly import to tune the parameters correctly. We use the grid_search function from sklearn to find the correct parameters for SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we do some coarse tuning on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "                     'dual': [True, False],\n",
    "                     'class_weight' : [None, 'auto']}]\n",
    "baseClf = svm.LinearSVC()\n",
    "clf = GridSearchCV(baseClf, tuned_parameters, cv=5)\n",
    "clf.fit(cleanedFeatureMatrix, cleanedResultVector)\n",
    "clf.get_params\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we do some fine tuning around the result of the coarse parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'C': list(range(75, 125, 5))}]\n",
    "baseClf = svm.LinearSVC()\n",
    "clf = GridSearchCV(baseClf, tuned_parameters, cv=5)\n",
    "clf.fit(cleanedFeatureMatrix, cleanedResultVector)\n",
    "print(clf.get_params)\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'C': list(range(55, 125, 5))}]\n",
    "baseClf = svm.LinearSVC(dual=False)\n",
    "clf = GridSearchCV(baseClf, tuned_parameters, cv=5)\n",
    "clf.fit(cleanedFeatureMatrix, cleanedResultVector)\n",
    "print(clf.get_params)\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunedSvmClf = svm.LinearSVC(C=80, dual=False)\n",
    "currCM, fig = printConfusionMatrix(tunedSvmClf, cleanedFeatureMatrix, cleanedResultVector, \"All features, SVM(C=80,dual=F)\")\n",
    "fig.savefig(saveDir+\"cm_all_tuned_svm.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem, AdditiveChi2Sampler, RBFSampler, SkewedChi2Sampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.lda import LDA\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = RBFSampler()\n",
    "cleanedFeatureMatrix_features = rbf_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "sgdClf = SGDClassifier()\n",
    "currCM, fig = printConfusionMatrix(sgdClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, SGD w RBF kernel\")\n",
    "fig.savefig(saveDir+\"cm_all_rbf_kernel_sgd.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = RBFSampler(gamma=1)\n",
    "cleanedFeatureMatrix_features = rbf_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "sgdClf = SGDClassifier()\n",
    "printConfusionMatrix(sgdClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, SGD w RBF kernel (gamma=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = RBFSampler()\n",
    "cleanedFeatureMatrix_features = rbf_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "ldaClf = LDA()\n",
    "currCM, fig = printConfusionMatrix(ldaClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, LDA w RBF kernel\")\n",
    "fig.savefig(saveDir+\"cm_all_rbf_kernel_lda.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = RBFSampler()\n",
    "cleanedFeatureMatrix_features = rbf_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "linearSVMClf = svm.LinearSVC()\n",
    "currCM, fig = printConfusionMatrix(linearSVMClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, SVM w RBF kernel\")\n",
    "fig.savefig(saveDir+\"cm_all_rbf_kernel_svm.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nys_feature = Nystroem(kernel='polynomial')\n",
    "cleanedFeatureMatrix_features = nys_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "sgdClf = SGDClassifier()\n",
    "currCM, fig = printConfusionMatrix(sgdClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, SGD w poly kernel\")\n",
    "fig.savefig(saveDir+\"cm_all_poly_kernel_sgd.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nys_feature = Nystroem(kernel='polynomial')\n",
    "cleanedFeatureMatrix_features = nys_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "ldaClf = LDA()\n",
    "currCM, fig = printConfusionMatrix(ldaClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, LDA w poly kernel\")\n",
    "fig.savefig(saveDir+\"cm_all_poly_kernel_lda.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nys_feature = Nystroem(kernel='polynomial')\n",
    "cleanedFeatureMatrix_features = nys_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "svmClf = svm.LinearSVC()\n",
    "currCM, fig = printConfusionMatrix(svmClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, SVM w poly kernel\")\n",
    "fig.savefig(saveDir+\"cm_all_poly_kernel_svm.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nys_feature = Nystroem(kernel='sigmoid')\n",
    "cleanedFeatureMatrix_features = nys_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "sgdClf = SGDClassifier()\n",
    "currCM, fig = printConfusionMatrix(sgdClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, SGD w sigmoid kernel\")\n",
    "fig.savefig(saveDir+\"cm_all_sigmoid_kernel_sgd.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nys_feature = Nystroem(kernel='sigmoid')\n",
    "cleanedFeatureMatrix_features = nys_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "ldaClf = LDA()\n",
    "currCM, fig = printConfusionMatrix(ldaClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, LDA w sigmoid kernel\")\n",
    "fig.savefig(saveDir+\"cm_all_sigmoid_kernel_lda.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nys_feature = Nystroem(kernel='sigmoid')\n",
    "cleanedFeatureMatrix_features = nys_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "svmClf = svm.LinearSVC()\n",
    "currCM, fig = printConfusionMatrix(svmClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, SVM w poly kernel\")\n",
    "fig.savefig(saveDir+\"cm_all_sigmoid_kernel_svm.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nys_feature = Nystroem(kernel='chi2')\n",
    "# cleanedFeatureMatrix_features = nys_feature.fit_transform(preprocessing.scale(cleanedFeatureMatrix))\n",
    "# sgdClf = SGDClassifier()\n",
    "# printConfusionMatrix(sgdClf, cleanedFeatureMatrix_features, cleanedResultVector, \"All features, SGD w sigmoid kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only for transport trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the prediction rate is best for walk and bike, which are the ones for which we get the most data from moves. It may be a mistake to use the same model for both types of trips because moves will do a good job for walk/bike and a horrible job for transport, because we don't allow users to specify 'transport' in the output.\n",
    "\n",
    "These also have zero carbon footprint. Let us see how well we do on the motorized trips alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transportTrips = cleanedFeatureMatrix[:,2] == 4\n",
    "print(np.count_nonzero(transportTrips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "printConfusionMatrix(forestClf, genericCleanedFM[transportTrips], cleanedResultVector[transportTrips], \"Generic features, motorized only, random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "printConfusionMatrix(forestClf, cleanedFeatureMatrix[transportTrips], cleanedResultVector[transportTrips], \"All features, transport only, random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClf = neighbors.KNeighborsClassifier()\n",
    "printConfusionMatrix(knnClf, genericCleanedFM[transportTrips], cleanedResultVector[transportTrips], \"Generic features, transport only, k-nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClf = neighbors.KNeighborsClassifier()\n",
    "printConfusionMatrix(knnClf, cleanedFeatureMatrix[transportTrips], cleanedResultVector[transportTrips], \"All features, transport only, k-nn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we are actually able to predict car trips with a fair degree of accuracy. But bus and train trips are pretty much a tossup. Ignore the entries for 0 and 1 above, since we stripped out all walk and bike trips, and so these are only trips which moves misclassified, and not the entire dataset. Now we know why the Zheng paper only attempted to distinguish between bus and car trips, and not bus, train and car. The new features helped in the decision tree case, but not by that much, and did not help us at all in the knn case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-specific models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserModelComparison(isTransportOnly):\n",
    "    userIds = Sections.distinct(\"user_id\")\n",
    "\n",
    "    # I'm not going to bother with testing against only the generic features\n",
    "    # because the main issue here is personalization\n",
    "\n",
    "    userIdList = []\n",
    "    numberOfSections = []\n",
    "    percentWalkBikeSections = []\n",
    "    percentAutoClassified = []\n",
    "    percentAutoClassifiedWalk = []\n",
    "    percentAutoClassifiedBike = []\n",
    "    percentAutoClassifiedBus = []\n",
    "    percentAutoClassifiedTrain = []\n",
    "    percentAutoClassifiedCar = []\n",
    "    autoClassifiedAccuracy = []\n",
    "    overallAccuracy = []\n",
    "\n",
    "    labels = [\"Number of sections\", \"% walk+bike trips\",\n",
    "              \"% autoclassified\", \"% auto classified walk\",\n",
    "              \"% auto classified bike\", \"% auto classified bus\",\n",
    "              \"% auto classified train\", \"% auto classified car\",\n",
    "              \"auto classified accuracy\", \"overall accuracy\"]\n",
    "    \n",
    "    for userId in userIds:\n",
    "        # decision tree with all features\n",
    "        if not isTransportOnly:\n",
    "            query = {\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}, {'user_id': userId}]}\n",
    "        else:\n",
    "            query = {\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}, {'mode': 4}, {'user_id': userId}]}\n",
    "        \n",
    "        wbQuery = {\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$in': ['1', '3', '7']}}, {'user_id': userId}]}\n",
    "        walkBikeTripCount = Sections.find(wbQuery).count()\n",
    "        (userFeatureMatrix, userResultVector) = generateFeatureMatrixAndResultVector(query)\n",
    "    \n",
    "        # we only focus on users who have enough history with us\n",
    "        if len(userResultVector) < 150:\n",
    "            print(\"Skipping user with userId %s who has %s unconfirmed sections\" % (userId, len(userResultVector)))\n",
    "            continue\n",
    "        \n",
    "        forestClf = ensemble.RandomForestClassifier()\n",
    "        # printConfusionMatrix(forestClf, userFeatureMatrix, userResultVector)\n",
    "        (pac5, pacm5, hcs5, s5) = kFoldValidationWithProb(forestClf, userFeatureMatrix, userResultVector, 5, 0.95)\n",
    "        userIdList.append(userId)\n",
    "        \n",
    "        numberOfSections.append(len(userResultVector))\n",
    "        percentWalkBikeSections.append(float(walkBikeTripCount)/len(userResultVector))\n",
    "        percentAutoClassified.append(pac5.mean())\n",
    "        percentAutoClassifiedWalk.append(pacm5[0].mean())\n",
    "        percentAutoClassifiedBike.append(pacm5[1].mean())\n",
    "        percentAutoClassifiedBus.append(pacm5[2].mean())\n",
    "        percentAutoClassifiedTrain.append(pacm5[3].mean())\n",
    "        percentAutoClassifiedCar.append(pacm5[4].mean())\n",
    "        autoClassifiedAccuracy.append(hcs5.mean())\n",
    "        overallAccuracy.append(s5.mean())\n",
    "    resultArray = np.array([numberOfSections, percentAutoClassified, percentAutoClassifiedWalk,\n",
    "                            percentAutoClassifiedBike, percentAutoClassifiedBus, percentAutoClassifiedTrain,\n",
    "                            percentAutoClassifiedCar, autoClassifiedAccuracy, overallAccuracy])\n",
    "    print(resultArray.shape)\n",
    "    return (userIdList, resultArray, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayUserVariation(userIds, ra, labels):\n",
    "    ''' ra has rows = plots and cols = users\n",
    "    '''\n",
    "    fig, (axes, axesNum) = plt.subplots(2, 1, figsize=(25, 25))\n",
    "    nUsers = len(userIds)\n",
    "    \n",
    "    for i in [1,-2,-1]:\n",
    "        # each row is one plot\n",
    "        print(ra[i])\n",
    "        axes.plot(np.arange(nUsers), ra[i], linewidth=2, label=labels[i])\n",
    "        axes.legend(loc='best')\n",
    "    for i in [0]:\n",
    "        # each row is one plot\n",
    "        print(ra[i])\n",
    "        axesNum.plot(np.arange(nUsers), ra[i], linewidth=2, label=labels[i])    \n",
    "        axesNum.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(userIds, userResultArray, labels) = getUserModelComparison(isTransportOnly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayUserVariation(userIds, userResultArray, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selIndices = [2, -2, -1, 1]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "fig, axes = displayHelpers.showCategoryChart(np.arange(len(userIds)), np.multiply([userResultArray[i] for i in selIndices], 100), [labels[i] for i in selIndices],\n",
    "                                             ['b', 'g', 'c', 'm', 'y', 'k', 'w'],\n",
    "                                             \"Percentage\",\n",
    "                                             \"Accuracy of various predictions\",\n",
    "                                             figsize=(12,5), width=0.2)\n",
    "ax2 = axes.twinx()\n",
    "# ax2.bar(np.arange(len(userResultArray[0])) + 3 * 0.2, userResultArray[0], 0.2, color = 'c')\n",
    "nSecLine, = ax2.plot(userResultArray[0], 'r-+', linewidth=2, label=\"Number of confirmed sections\")\n",
    "axes.set_ylim(top=115)\n",
    "axes.axhline(98, linewidth=2, label = \"98%\")\n",
    "axes.axhline(85, linewidth=2, label = \"85%\")\n",
    "axes.text(x=15.5, y=98.5, s=\"98%\")\n",
    "axes.text(x=15.5, y=85.5, s=\"85%\")\n",
    "axes.get_legend().set_bbox_to_anchor((0.4, -0.1))\n",
    "print(axes.get_legend_handles_labels())\n",
    "ax2.legend([nSecLine], [\"Number of sections\"], loc=\"upper right\", framealpha=0.3, bbox_to_anchor=(1, -0.1))\n",
    "ax2.set_ylabel(\"Count (number of sections)\")\n",
    "axes.set_xlabel(\"Users\")\n",
    "ax2.set_ylim(bottom=0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(userResultArray[1], userResultArray[-1], \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pick users with really high accuracy. Unfortunately, they also have the least confirmed sections. Let us see whether this is because they are heavy walkers or otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIds[5], userIds[6], userIds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [2,5,6]:\n",
    "    userId = userIds[i]\n",
    "    query = {\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}, {'user_id': userId}]}\n",
    "    (userFeatureMatrix, userResultVector) = generateFeatureMatrixAndResultVector(query)\n",
    "    indicesToStrip = (userResultVector == 2) | (userResultVector == 4) | (userResultVector == 8)\n",
    "    for mode in [1,3,5,6,7,9]:\n",
    "        # nFolds = 5\n",
    "        if np.count_nonzero(userResultVector == mode) <= 10:\n",
    "            print(\"number of instances of mode %s = %s\" % (mode, np.count_nonzero(userResultVector == mode)))\n",
    "            indicesToStrip = indicesToStrip | (userResultVector == mode)\n",
    "    userStrippedIndices = np.logical_not(indicesToStrip)\n",
    "    strippedUserFeatureMatrix = userFeatureMatrix[userStrippedIndices]\n",
    "    strippedUserResultVector = userResultVector[userStrippedIndices]\n",
    "    forestClf = ensemble.RandomForestClassifier()\n",
    "    printConfusionMatrix(forestClf, strippedUserFeatureMatrix, strippedUserResultVector, \"All features, random forest, user %s\" % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's quite a bit of variability in both the overall accuracy, and in the number of trips for a user. The two don't seem to be correlated though. We get some fairly uneven improvement - for some users, the general classification is over 90%. We are also able to classify over 80% of the trips for some users.\n",
    "\n",
    "But that might just be due to a higher ratio of walk trips, which are classified more accurately. I can explore this only for transport, but first, I'm going to try to build a gesture library and build the associated features. Then maybe Mogeng can continue some of the exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(userIdsTransOnly, userResultArrayTransOnly, labelsTransOnly) = getUserModelComparison(isTransportOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayUserVariation(userIdsTransOnly, userResultArrayTransOnly, labelsTransOnly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So looking at transport-only trips, and focusing on users with enough transport history (50+ motorized transport trips), we are able to get an overall accuracy of around 70 - 80% even for the motorized trips. However, there are some clear outliers, like the one who has only 60% accuracy. Also, because our current threshold for high confidence is set so high, the high confidence predictions are > 95% correct as before. We have to decide what to use.\n",
    "\n",
    "We can autoclassify 20 - 50% of the motorized transport trips. In general, this is related to the number of trips - there is a very clear spike in the data for user 4. But the correlation is not exact. In particular, user 5 has > 50 trips, but only ~ 10% autoclassified trips.\n",
    "\n",
    "It might be worthwhile to take a closer look at these 6 users, see what their transport trips look like, and get a sense of what the difference between user 4 and user 5 is, for example. This might help us figure out how to build better user models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildRouteLibrary(userId, threshold):\n",
    "    '''\n",
    "    Here we attempt to build a route library for each user.\n",
    "    Then, the probability of the top match can be a factor in our machine learning.\n",
    "    Let us just start with the start and end points instead of a full dynamic time warp.\n",
    "    \n",
    "    userSections = Sections.find({\"$and\": [{'type': 'move'}, {'confirmed_mode': {'$ne': ''}}, {'user_id': userId}]})\n",
    "    existingRoutes = RouteLibrary()\n",
    "    for section in userSections:\n",
    "        existingRoutes.update(section)\n",
    "    return existingRoutes\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A summary comparision of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCMList = []\n",
    "saveDir = \"/tmp/ml_results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(saveDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices], cleanedResultVector, 5)\n",
    "currCM, fig = printConfusionMatrix(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices], cleanedResultVector, \"Generic\")\n",
    "modelCMList.append(currCM)\n",
    "fig.savefig(saveDir+\"cm_generic.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic + Advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+AdvancedFeatureIndices], cleanedResultVector, 5)\n",
    "currCM, fig = printConfusionMatrix(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+AdvancedFeatureIndices], cleanedResultVector, \"Generic + Advanced\")\n",
    "modelCMList.append(currCM)\n",
    "fig.savefig(saveDir+\"cm_generic_advanced.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic + Advanced + Location model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+AdvancedFeatureIndices\n",
    "                                                            +LocationFeatureIndices], cleanedResultVector, 5)\n",
    "currCM, fig = printConfusionMatrix(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+AdvancedFeatureIndices\n",
    "                                                            +LocationFeatureIndices], cleanedResultVector, \"Generic + Advanced + Location\")\n",
    "modelCMList.append(currCM)\n",
    "fig.savefig(saveDir+\"cm_generic_advanced_location.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic + BusTrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+BusTrainFeatureIndices], cleanedResultVector, 5)\n",
    "currCM, fig = printConfusionMatrix(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+BusTrainFeatureIndices], cleanedResultVector, \"Generic + BusTrain\")\n",
    "modelCMList.append(currCM)\n",
    "fig.savefig(saveDir+\"cm_generic_bustrain.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic + Advanced + BusTrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+AdvancedFeatureIndices+BusTrainFeatureIndices], cleanedResultVector, 5)\n",
    "currCM, fig = printConfusionMatrix(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+AdvancedFeatureIndices+BusTrainFeatureIndices], cleanedResultVector, \"Generic + Advanced + BusTrain\")\n",
    "modelCMList.append(currCM)\n",
    "fig.savefig(saveDir+\"cm_generic_advanced_bustrain.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic + Advanced + BusTrain + Location model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+AdvancedFeatureIndices+BusTrainFeatureIndices\n",
    "                                                            +LocationFeatureIndices], cleanedResultVector, 5)\n",
    "currCM, fig = printConfusionMatrix(forestClf, cleanedFeatureMatrix[:,genericFeatureIndices+AdvancedFeatureIndices+BusTrainFeatureIndices\n",
    "                                                            +LocationFeatureIndices], cleanedResultVector, \"Gen + Adv + BusTrain + Loc\")\n",
    "modelCMList.append(currCM)\n",
    "fig.savefig(saveDir+\"cm_generic_advanced_bustrain_location.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic + Advanced + BusTrain + Location + Time model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClf = ensemble.RandomForestClassifier()\n",
    "exploreKFoldValidationSpace(forestClf, cleanedFeatureMatrix, cleanedResultVector, 5)\n",
    "currCM, fig = printConfusionMatrix(forestClf, cleanedFeatureMatrix, cleanedResultVector, \"Gen + Adv + BusTrain + Loc + Time\")\n",
    "modelCMList.append(currCM)\n",
    "fig.savefig(saveDir+\"cm_generic_advanced_bustrain_location_time.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that with all the features in, we can have the best prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmDiagList = []\n",
    "modelLabels = [\"Generic\", \"G+A\", \"G+A+L\", \"G+B\", \"G+A+B\", \"G+A+B+L\", \"G+A+B+L+T\"]\n",
    "for currCM in modelCMList:\n",
    "    cmDiagList.append(np.diag(currCM) * 100)\n",
    "accuracyMatrix = np.vstack(cmDiagList)\n",
    "print(len(modelLabels), accuracyMatrix.shape)\n",
    "np.set_printoptions(precision=4)\n",
    "print(accuracyMatrix)\n",
    "np.set_printoptions(precision=0)\n",
    "print(accuracyMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmDiagList = []\n",
    "modelLabels = [\"Generic\", \"G+A\", \"G+A+L\", \"G+B\", \"G+A+B\", \"G+A+B+L\", \"G+A+B+L+T\"]\n",
    "for currCM in modelCMList:\n",
    "    cmDiagList.append(np.diag(currCM) * 100)\n",
    "accuracyMatrix = np.vstack(cmDiagList).round(decimals=0).astype(object)\n",
    "print(len(modelLabels), accuracyMatrix.shape)\n",
    "outputMatrix = np.insert(accuracyMatrix, 0, modelLabels, axis=1)\n",
    "print(outputMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
